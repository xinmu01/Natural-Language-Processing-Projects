{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Construct the emission matrix p(w/t)\n",
    "In the trigram model, I label the word using the tag consists of its own tag with the previous tag. For example, if there are 3 different tags, A, B, C. Now the tag list for the trigram model is [start, startA,AB,BA,AC,CA,BC,CB,AA,BB,CC,stop].  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Construct bag of word for word and tag seperately\n",
    "word_count = {}\n",
    "tag_count = {}\n",
    "with open (\"C:/Users/Xin/Desktop/Github-repo/Natural_Language_Processing_Projects/Project_3_Sequence_Tagging/hw3-data/train.txt\") as train_file:\n",
    "    for line in train_file:\n",
    "        line_list = line.split()\n",
    "        temp_tag_list = []\n",
    "        for i in range(len(line_list)):\n",
    "            temp = line_list[i].split('/')\n",
    "            if temp[0] not in word_count:\n",
    "                word_count[temp[0]]=1\n",
    "            if temp[0] in word_count:\n",
    "                word_count[temp[0]]+=1\n",
    "            temp_tag_list.append(temp[1])\n",
    "        ## Construct bigram tags\n",
    "        temp_tag_list_prev = [\"<s>\"]\n",
    "        for i in range(len(temp_tag_list)-1):\n",
    "            temp_tag_list_prev.append(temp_tag_list[i])\n",
    "        for i in range(len(temp_tag_list)):\n",
    "            tag_temp= \"\".join([temp_tag_list_prev[i],temp_tag_list[i]])\n",
    "            if tag_temp not in tag_count:\n",
    "                tag_count[tag_temp] = 1\n",
    "            else:\n",
    "                tag_count[tag_temp] += 1\n",
    "### word_count\n",
    "#{'azaleas': 5,\n",
    "# 'termination': 3,\n",
    "# 'planting': 26,\n",
    "# ...\n",
    "\n",
    "### tag_count\n",
    "#{'<s>A': 28,\n",
    "# '<s>D': 11005,\n",
    "# '<s>E': 1978,\n",
    "# '<s>F': 12612,\n",
    "# '<s>N': 153233,\n",
    "# '<s>R': 11318,\n",
    "# 'AA': 2564,\n",
    "# 'AD': 19,\n",
    "# 'AE': 2,\n",
    "# ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EE': 5354, 'ND': 11910, 'DA': 38, 'AF': 46, 'EA': 1, 'FN': 27764, 'NN': 1101003, 'NE': 653, '<s>E': 1978, 'DF': 736, '<s>R': 11318, 'AD': 19, 'AA': 2564, 'FA': 89, '<s>D': 11005, 'FD': 1999, 'NF': 20663, '<s>F': 12612, 'RE': 440, 'RD': 2172, 'EF': 64, '<s>N': 153233, 'RR': 63028, 'NR': 21839, 'NA': 174, '<s>A': 28, 'DD': 38134, 'DE': 114, 'AE': 2, 'RA': 136, 'DR': 2685, 'ED': 142, 'DN': 18923, 'FE': 83, 'AR': 48, 'EN': 2378, 'FF': 39789, 'ER': 499, 'RN': 30003, 'FR': 2317, 'RF': 4145, 'AN': 305}\n"
     ]
    }
   ],
   "source": [
    "print (tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Construct the data structure to store the c(t,w). Here t is the double tag created above.  \n",
    "# Use the dictionary to store the counts\n",
    "# For the dictionary word_tag_pair_counts, the keys are the tags in the training set, the value is a dictionary, in which the keys \n",
    "# are the words, the the value are the counts for this word-key pair \n",
    "tag_word_pair_counts = {}\n",
    "\n",
    "with open (\"C:/Users/Xin/Desktop/Github-repo/Natural_Language_Processing_Projects/Project_3_Sequence_Tagging/hw3-data/train.txt\") as train_file:\n",
    "    for line in train_file:\n",
    "        line_list = line.split()\n",
    "        \n",
    "        temp_tag_list_uni = []\n",
    "        temp_tag_list_double = []\n",
    "        temp_word_list = []\n",
    "        for i in range(len(line_list)):\n",
    "            temp = line_list[i].split('/')\n",
    "            temp_word_list.append(temp[0])\n",
    "            temp_tag_list_uni.append(temp[1])\n",
    "        \n",
    "        ## Construct the double tag    \n",
    "        temp_tag_list_uni_prev = [\"<s>\"]\n",
    "        for i in range(len(temp_tag_list_uni)-1):\n",
    "            temp_tag_list_uni_prev.append(temp_tag_list_uni[i])\n",
    "        for i in range(len(temp_tag_list_uni)):\n",
    "            temp_tag_list_double.append(\"\".join([temp_tag_list_uni_prev[i],temp_tag_list_uni[i]]))\n",
    "        \n",
    "        for i in range(len(temp_tag_list_double)):\n",
    "            if temp_tag_list_double[i] not in tag_word_pair_counts:\n",
    "                tag_word_pair_counts[temp_tag_list_double[i]] = {}\n",
    "                tag_word_pair_counts[temp_tag_list_double[i]][temp_word_list[i]] = 1\n",
    "            else:\n",
    "                if temp_word_list[i] not in tag_word_pair_counts[temp_tag_list_double[i]]:\n",
    "                    tag_word_pair_counts[temp_tag_list_double[i]][temp_word_list[i]] = 1\n",
    "                else:\n",
    "                    tag_word_pair_counts[temp_tag_list_double[i]][temp_word_list[i]] += 1\n",
    "#tag_word_pair_counts\n",
    "#{'<s>A': {'--': 8,\n",
    "#  'and': 1,\n",
    "#  'basketball': 1,\n",
    "#  'but': 1,\n",
    "#  'criminal': 1,\n",
    "#  'frankly': 1,\n",
    "#  'i': 2,\n",
    "#  'like': 1,\n",
    "#  'not': 3,\n",
    "# ...\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Construct the emission matrix, each entry is p(w/t), I use add delta smoothing to deal with unknown word\n",
    "\n",
    "## I use a dictionary of dictionary to represent this matrix\n",
    "## The key of the outer dictionary is the double tag, and the the key of the sub-dictionary is their corresponding word\n",
    "emission_matrix = {}\n",
    "delta = 0.1 \n",
    "V = len(word_count) + 1 ## assum only one kind of unseen words\n",
    "for tag in tag_count:\n",
    "    emission_matrix[tag]={}\n",
    "    sum_tag_allword = 0\n",
    "    for word in tag_word_pair_counts[tag]:\n",
    "        sum_tag_allword += tag_word_pair_counts[tag][word]\n",
    "    sum_tag_allword += V*delta ## Add delta smoothing\n",
    "    for word in tag_word_pair_counts[tag]:\n",
    "        emission_matrix[tag][word] = (tag_word_pair_counts[tag][word]+delta)/sum_tag_allword\n",
    "    emission_matrix[tag]['unk'] = delta/sum_tag_allword\n",
    "#emission_matrix\n",
    "#{'<s>A': {'--': 0.0039187227866473145,\n",
    "#  'and': 0.0005321722302854379,\n",
    "#  'basketball': 0.0005321722302854379,\n",
    "#  'but': 0.0005321722302854379,\n",
    "#  'criminal': 0.0005321722302854379,\n",
    "#  'frankly': 0.0005321722302854379,\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(you/ND): 0.6603412430998639\n",
      "p(you/FN): 0.011478710196960038\n",
      "p(you/NN): 0.012527265507569068\n",
      "p(you/NE): 0.0018945022288261513\n",
      "p(you/<s>E): 0.0002738361961662933\n",
      "p(you/<s>R): 0.01498090888672606\n",
      "p(you/AD): 0.005393586005830904\n",
      "p(you/AA): 0.0037149684988051273\n",
      "p(you/FA): 0.0005169172932330828\n",
      "p(you/<s>D): 0.15440815700705304\n",
      "p(you/FD): 0.27144626052501236\n",
      "p(you/<s>F): 7.50801993038018e-05\n",
      "p(you/RE): 0.0004437273093989512\n",
      "p(you/RD): 0.3818807884113037\n",
      "p(you/<s>N): 0.012243675614405687\n",
      "p(you/RR): 0.009069113375443773\n",
      "p(you/NR): 0.015876539073624258\n",
      "p(you/NA): 0.002756439222774514\n",
      "p(you/DD): 0.008167176959649516\n",
      "p(you/RA): 0.0018850574712643677\n",
      "p(you/DR): 0.017379339542760372\n",
      "p(you/ED): 0.05048143053645117\n",
      "p(you/DN): 0.026242724930827212\n",
      "p(you/FE): 0.0005183788878416588\n",
      "p(you/EN): 0.02583201267828843\n",
      "p(you/ER): 0.007919621749408984\n",
      "p(you/RN): 0.017230509955683166\n",
      "p(you/FR): 0.010583103764921947\n",
      "p(you/AN): 0.0013225255972696246\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "## Obtain p(you/t)\n",
    "count = 0\n",
    "for tag in tag_count:    \n",
    "    if \"you\" not in emission_matrix[tag]:\n",
    "        continue\n",
    "    else:\n",
    "        count += 1 \n",
    "        print (\"p(you/{}): {}\".format(tag,emission_matrix[tag]['you']))\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construct transtion matrix p(t'/t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Considering the start and stop tag, there are 44 different tags \n",
    "## t =  [<s>,'AD', 'DA'...]\n",
    "## t' = ['AD', 'DA', </s>...]\n",
    "\n",
    "## Construct a matrix to store the counts of c(t',t) \n",
    "## I use a dictionary of dictionary to represent this matrix\n",
    "## The key of the outer dictionary is t, and the the key of the sub-dictionary is t'\n",
    "\n",
    "tag_tag_count = {}\n",
    "with open (\"C:/Users/Xin/Desktop/Github-repo/Natural_Language_Processing_Projects/Project_3_Sequence_Tagging/hw3-data/train.txt\") as train_file:\n",
    "    for line in train_file:\n",
    "        line_list = line.split()\n",
    "        \n",
    "        temp_tag_list_uni = []\n",
    "        \n",
    "\n",
    "        for i in range(len(line_list)):\n",
    "            temp = line_list[i].split('/')\n",
    "            temp_tag_list_uni.append(temp[1])\n",
    "            \n",
    "        ## Construct the double tag    \n",
    "        temp_tag_list_uni_prev = [\"<s>\"]\n",
    "        for i in range(len(temp_tag_list_uni)-1):\n",
    "            temp_tag_list_uni_prev.append(temp_tag_list_uni[i])\n",
    "            \n",
    "        temp_tag_list_double = [\"<s>\"]\n",
    "        \n",
    "        for i in range(len(temp_tag_list_uni)):\n",
    "            temp_tag_list_double.append(\"\".join([temp_tag_list_uni_prev[i],temp_tag_list_uni[i]]))\n",
    "        \n",
    "        temp_tag_list_double.append(\"</s>\")\n",
    "        \n",
    "        \n",
    "        for i in range(len(temp_tag_list_double)-1): ## i go through all the t in one sentence\n",
    "            if temp_tag_list_double[i] not in tag_tag_count:\n",
    "                tag_tag_count[temp_tag_list_double[i]]={}\n",
    "                tag_tag_count[temp_tag_list_double[i]][temp_tag_list_double[i+1]]=1\n",
    "            else:\n",
    "                if temp_tag_list_double[i+1] not in tag_tag_count[temp_tag_list_double[i]]:\n",
    "                    tag_tag_count[temp_tag_list_double[i]][temp_tag_list_double[i+1]]=1\n",
    "                else:\n",
    "                    tag_tag_count[temp_tag_list_double[i]][temp_tag_list_double[i+1]]+=1\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s>': {'<s>A': 28,\n",
       "  '<s>D': 11005,\n",
       "  '<s>E': 1978,\n",
       "  '<s>F': 12612,\n",
       "  '<s>N': 153233,\n",
       "  '<s>R': 11318},\n",
       " '<s>A': {'AA': 26, 'AD': 1, 'AN': 1},\n",
       " '<s>D': {'</s>': 29, 'DD': 8991, 'DE': 4, 'DF': 6, 'DN': 1688, 'DR': 287},\n",
       " '<s>E': {'</s>': 1, 'EE': 1962, 'EN': 12, 'ER': 3},\n",
       " '<s>F': {'</s>': 38, 'FD': 18, 'FF': 11916, 'FN': 619, 'FR': 21},\n",
       " '<s>N': {'</s>': 1934,\n",
       "  'NA': 6,\n",
       "  'ND': 864,\n",
       "  'NE': 155,\n",
       "  'NF': 526,\n",
       "  'NN': 145678,\n",
       "  'NR': 4070},\n",
       " '<s>R': {'</s>': 14, 'RD': 25, 'RE': 6, 'RF': 24, 'RN': 259, 'RR': 10990},\n",
       " 'AA': {'</s>': 45,\n",
       "  'AA': 2107,\n",
       "  'AD': 18,\n",
       "  'AE': 2,\n",
       "  'AF': 46,\n",
       "  'AN': 304,\n",
       "  'AR': 42},\n",
       " 'AD': {'DA': 2, 'DD': 15, 'DN': 2},\n",
       " 'AE': {'EE': 2},\n",
       " 'AF': {'FA': 1, 'FF': 43, 'FN': 1, 'FR': 1},\n",
       " 'AN': {'</s>': 20, 'NN': 277, 'NR': 8},\n",
       " 'AR': {'RN': 3, 'RR': 45},\n",
       " 'DA': {'AA': 37, 'AR': 1},\n",
       " 'DD': {'</s>': 4676,\n",
       "  'DA': 31,\n",
       "  'DD': 14869,\n",
       "  'DE': 106,\n",
       "  'DF': 729,\n",
       "  'DN': 15479,\n",
       "  'DR': 2244},\n",
       " 'DE': {'EE': 113, 'EN': 1},\n",
       " 'DF': {'</s>': 1, 'FD': 1, 'FF': 715, 'FN': 19},\n",
       " 'DN': {'</s>': 450, 'NA': 1, 'ND': 30, 'NF': 8, 'NN': 18154, 'NR': 280},\n",
       " 'DR': {'</s>': 8, 'RD': 7, 'RF': 1, 'RN': 65, 'RR': 2604},\n",
       " 'EA': {'AA': 1},\n",
       " 'ED': {'DD': 122, 'DN': 18, 'DR': 2},\n",
       " 'EE': {'</s>': 185,\n",
       "  'EA': 1,\n",
       "  'ED': 141,\n",
       "  'EE': 2242,\n",
       "  'EF': 64,\n",
       "  'EN': 2240,\n",
       "  'ER': 481},\n",
       " 'EF': {'FF': 63, 'FR': 1},\n",
       " 'EN': {'</s>': 49, 'ND': 4, 'NE': 1, 'NN': 2285, 'NR': 39},\n",
       " 'ER': {'</s>': 1, 'RD': 3, 'RE': 1, 'RN': 6, 'RR': 488},\n",
       " 'FA': {'</s>': 1, 'AA': 88},\n",
       " 'FD': {'</s>': 10,\n",
       "  'DA': 1,\n",
       "  'DD': 1683,\n",
       "  'DE': 2,\n",
       "  'DF': 1,\n",
       "  'DN': 275,\n",
       "  'DR': 27},\n",
       " 'FE': {'EE': 69, 'EN': 13, 'ER': 1},\n",
       " 'FF': {'</s>': 5941,\n",
       "  'FA': 85,\n",
       "  'FD': 1968,\n",
       "  'FE': 83,\n",
       "  'FF': 2781,\n",
       "  'FN': 26656,\n",
       "  'FR': 2275},\n",
       " 'FN': {'</s>': 779, 'ND': 40, 'NE': 3, 'NF': 21, 'NN': 26445, 'NR': 476},\n",
       " 'FR': {'</s>': 8, 'RA': 1, 'RD': 7, 'RE': 2, 'RF': 3, 'RN': 59, 'RR': 2237},\n",
       " 'NA': {'AA': 169, 'AR': 5},\n",
       " 'ND': {'</s>': 36, 'DA': 2, 'DD': 10508, 'DN': 1272, 'DR': 92},\n",
       " 'NE': {'EE': 645, 'EN': 8},\n",
       " 'NF': {'</s>': 33, 'FA': 3, 'FD': 9, 'FF': 20214, 'FN': 398, 'FR': 6},\n",
       " 'NN': {'</s>': 173798,\n",
       "  'NA': 164,\n",
       "  'ND': 10912,\n",
       "  'NE': 488,\n",
       "  'NF': 20083,\n",
       "  'NN': 879108,\n",
       "  'NR': 16450},\n",
       " 'NR': {'</s>': 8,\n",
       "  'RA': 2,\n",
       "  'RD': 33,\n",
       "  'RE': 6,\n",
       "  'RF': 31,\n",
       "  'RN': 699,\n",
       "  'RR': 21060},\n",
       " 'RA': {'AA': 136},\n",
       " 'RD': {'DA': 2, 'DD': 1946, 'DE': 2, 'DN': 189, 'DR': 33},\n",
       " 'RE': {'ED': 1, 'EE': 321, 'EN': 104, 'ER': 14},\n",
       " 'RF': {'</s>': 1, 'FD': 3, 'FF': 4057, 'FN': 71, 'FR': 13},\n",
       " 'RN': {'</s>': 337,\n",
       "  'NA': 3,\n",
       "  'ND': 60,\n",
       "  'NE': 6,\n",
       "  'NF': 25,\n",
       "  'NN': 29056,\n",
       "  'NR': 516},\n",
       " 'RR': {'</s>': 1771,\n",
       "  'RA': 133,\n",
       "  'RD': 2097,\n",
       "  'RE': 425,\n",
       "  'RF': 4086,\n",
       "  'RN': 28912,\n",
       "  'RR': 25604}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Construct transition matrix\n",
    "## Construct the transition matrix to store the p(t'/t). The data structure is the same as that store c(t',t)\n",
    "transition_matrix = {}\n",
    "for tag in tag_tag_count:\n",
    "    transition_matrix[tag] = {}\n",
    "    sum_temp = 0\n",
    "    for taggg in tag_tag_count[tag]:\n",
    "        sum_temp += tag_tag_count[tag][taggg]\n",
    "    for taggg in tag_tag_count[tag]:\n",
    "        transition_matrix[tag][taggg] = tag_tag_count[tag][taggg]/sum_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s>': {'<s>A': 0.0001472335860843228,\n",
       "  '<s>D': 0.05786805767349901,\n",
       "  '<s>E': 0.010401001188385373,\n",
       "  '<s>F': 0.0663182138462671,\n",
       "  '<s>N': 0.8057515748735369,\n",
       "  '<s>R': 0.05951391883222733},\n",
       " '<s>A': {'AA': 0.9285714285714286,\n",
       "  'AD': 0.03571428571428571,\n",
       "  'AN': 0.03571428571428571},\n",
       " '<s>D': {'</s>': 0.002635165833711949,\n",
       "  'DD': 0.8169922762380736,\n",
       "  'DE': 0.0003634711494775102,\n",
       "  'DF': 0.0005452067242162653,\n",
       "  'DN': 0.15338482507950932,\n",
       "  'DR': 0.026079054975011357},\n",
       " '<s>E': {'</s>': 0.0005055611729019212,\n",
       "  'EE': 0.9919110212335692,\n",
       "  'EN': 0.006066734074823054,\n",
       "  'ER': 0.0015166835187057635},\n",
       " '<s>F': {'</s>': 0.0030130034887408817,\n",
       "  'FD': 0.0014272121788772598,\n",
       "  'FF': 0.9448144624167459,\n",
       "  'FN': 0.049080241040279096,\n",
       "  'FR': 0.001665080875356803},\n",
       " '<s>N': {'</s>': 0.012621302199917772,\n",
       "  'NA': 3.915605646303342e-05,\n",
       "  'ND': 0.0056384721306768125,\n",
       "  'NE': 0.0010115314586283633,\n",
       "  'NF': 0.0034326809499259296,\n",
       "  'NN': 0.9506959989036304,\n",
       "  'NR': 0.02656085830075767},\n",
       " '<s>R': {'</s>': 0.0012369676621311187,\n",
       "  'RD': 0.0022088708252341405,\n",
       "  'RE': 0.0005301289980561937,\n",
       "  'RF': 0.002120515992224775,\n",
       "  'RN': 0.022883901749425693,\n",
       "  'RR': 0.9710196147729281},\n",
       " 'AA': {'</s>': 0.017550702028081122,\n",
       "  'AA': 0.8217628705148206,\n",
       "  'AD': 0.0070202808112324495,\n",
       "  'AE': 0.00078003120124805,\n",
       "  'AF': 0.01794071762870515,\n",
       "  'AN': 0.11856474258970359,\n",
       "  'AR': 0.01638065522620905},\n",
       " 'AD': {'DA': 0.10526315789473684,\n",
       "  'DD': 0.7894736842105263,\n",
       "  'DN': 0.10526315789473684},\n",
       " 'AE': {'EE': 1.0},\n",
       " 'AF': {'FA': 0.021739130434782608,\n",
       "  'FF': 0.9347826086956522,\n",
       "  'FN': 0.021739130434782608,\n",
       "  'FR': 0.021739130434782608},\n",
       " 'AN': {'</s>': 0.06557377049180328,\n",
       "  'NN': 0.9081967213114754,\n",
       "  'NR': 0.02622950819672131},\n",
       " 'AR': {'RN': 0.0625, 'RR': 0.9375},\n",
       " 'DA': {'AA': 0.9736842105263158, 'AR': 0.02631578947368421},\n",
       " 'DD': {'</s>': 0.12262023391199454,\n",
       "  'DA': 0.0008129228509991084,\n",
       "  'DD': 0.38991451198405624,\n",
       "  'DE': 0.0027796716840614672,\n",
       "  'DF': 0.01911679865736613,\n",
       "  'DN': 0.4059107358262967,\n",
       "  'DR': 0.05884512508522578},\n",
       " 'DE': {'EE': 0.9912280701754386, 'EN': 0.008771929824561403},\n",
       " 'DF': {'</s>': 0.001358695652173913,\n",
       "  'FD': 0.001358695652173913,\n",
       "  'FF': 0.9714673913043478,\n",
       "  'FN': 0.025815217391304348},\n",
       " 'DN': {'</s>': 0.023780584473920625,\n",
       "  'NA': 5.2845743275379165e-05,\n",
       "  'ND': 0.001585372298261375,\n",
       "  'NF': 0.0004227659462030333,\n",
       "  'NN': 0.9593616234212334,\n",
       "  'NR': 0.014796808117106167},\n",
       " 'DR': {'</s>': 0.0029795158286778397,\n",
       "  'RD': 0.0026070763500931097,\n",
       "  'RF': 0.00037243947858472997,\n",
       "  'RN': 0.024208566108007448,\n",
       "  'RR': 0.9698324022346368},\n",
       " 'EA': {'AA': 1.0},\n",
       " 'ED': {'DD': 0.8591549295774648,\n",
       "  'DN': 0.1267605633802817,\n",
       "  'DR': 0.014084507042253521},\n",
       " 'EE': {'</s>': 0.0345536047814718,\n",
       "  'EA': 0.00018677624206200972,\n",
       "  'ED': 0.02633545013074337,\n",
       "  'EE': 0.41875233470302575,\n",
       "  'EF': 0.011953679491968622,\n",
       "  'EN': 0.41837878221890173,\n",
       "  'ER': 0.08983937243182667},\n",
       " 'EF': {'FF': 0.984375, 'FR': 0.015625},\n",
       " 'EN': {'</s>': 0.02060555088309504,\n",
       "  'ND': 0.001682085786375105,\n",
       "  'NE': 0.00042052144659377626,\n",
       "  'NN': 0.9608915054667788,\n",
       "  'NR': 0.016400336417157275},\n",
       " 'ER': {'</s>': 0.002004008016032064,\n",
       "  'RD': 0.006012024048096192,\n",
       "  'RE': 0.002004008016032064,\n",
       "  'RN': 0.012024048096192385,\n",
       "  'RR': 0.9779559118236473},\n",
       " 'FA': {'</s>': 0.011235955056179775, 'AA': 0.9887640449438202},\n",
       " 'FD': {'</s>': 0.0050025012506253125,\n",
       "  'DA': 0.0005002501250625312,\n",
       "  'DD': 0.8419209604802401,\n",
       "  'DE': 0.0010005002501250625,\n",
       "  'DF': 0.0005002501250625312,\n",
       "  'DN': 0.1375687843921961,\n",
       "  'DR': 0.013506753376688344},\n",
       " 'FE': {'EE': 0.8313253012048193,\n",
       "  'EN': 0.1566265060240964,\n",
       "  'ER': 0.012048192771084338},\n",
       " 'FF': {'</s>': 0.14931262409208576,\n",
       "  'FA': 0.002136268818015029,\n",
       "  'FD': 0.04946090628063032,\n",
       "  'FE': 0.0020860036693558523,\n",
       "  'FF': 0.06989368921058584,\n",
       "  'FN': 0.6699339013295131,\n",
       "  'FR': 0.057176606599814016},\n",
       " 'FN': {'</s>': 0.02805791672669644,\n",
       "  'ND': 0.0014407145944388417,\n",
       "  'NE': 0.00010805359458291313,\n",
       "  'NF': 0.0007563751620803919,\n",
       "  'NN': 0.9524924362483792,\n",
       "  'NR': 0.017144503673822215},\n",
       " 'FR': {'</s>': 0.0034527406128614588,\n",
       "  'RA': 0.00043159257660768235,\n",
       "  'RD': 0.0030211480362537764,\n",
       "  'RE': 0.0008631851532153647,\n",
       "  'RF': 0.001294777729823047,\n",
       "  'RN': 0.025463962019853258,\n",
       "  'RR': 0.9654725938713854},\n",
       " 'NA': {'AA': 0.9712643678160919, 'AR': 0.028735632183908046},\n",
       " 'ND': {'</s>': 0.003022670025188917,\n",
       "  'DA': 0.00016792611251049538,\n",
       "  'DD': 0.8822837951301428,\n",
       "  'DN': 0.10680100755667506,\n",
       "  'DR': 0.007724601175482787},\n",
       " 'NE': {'EE': 0.9877488514548239, 'EN': 0.01225114854517611},\n",
       " 'NF': {'</s>': 0.001597057542467212,\n",
       "  'FA': 0.00014518704931520108,\n",
       "  'FD': 0.00043556114794560325,\n",
       "  'FF': 0.9782703382858249,\n",
       "  'FN': 0.019261481875816677,\n",
       "  'FR': 0.00029037409863040217},\n",
       " 'NN': {'</s>': 0.15785424744528398,\n",
       "  'NA': 0.00014895508913236386,\n",
       "  'ND': 0.009910963003733867,\n",
       "  'NE': 0.00044323221644264365,\n",
       "  'NF': 0.01824064057954429,\n",
       "  'NN': 0.7984610396156959,\n",
       "  'NR': 0.014940922050166984},\n",
       " 'NR': {'</s>': 0.00036631713906314393,\n",
       "  'RA': 9.157928476578598e-05,\n",
       "  'RD': 0.0015110581986354686,\n",
       "  'RE': 0.00027473785429735795,\n",
       "  'RF': 0.0014194789138696827,\n",
       "  'RN': 0.0320069600256422,\n",
       "  'RR': 0.9643298685837264},\n",
       " 'RA': {'AA': 1.0},\n",
       " 'RD': {'DA': 0.0009208103130755065,\n",
       "  'DD': 0.8959484346224678,\n",
       "  'DE': 0.0009208103130755065,\n",
       "  'DN': 0.08701657458563536,\n",
       "  'DR': 0.015193370165745856},\n",
       " 'RE': {'ED': 0.0022727272727272726,\n",
       "  'EE': 0.7295454545454545,\n",
       "  'EN': 0.23636363636363636,\n",
       "  'ER': 0.031818181818181815},\n",
       " 'RF': {'</s>': 0.00024125452352231604,\n",
       "  'FD': 0.0007237635705669482,\n",
       "  'FF': 0.9787696019300361,\n",
       "  'FN': 0.01712907117008444,\n",
       "  'FR': 0.0031363088057901087},\n",
       " 'RN': {'</s>': 0.0112322101123221,\n",
       "  'NA': 9.999000099990002e-05,\n",
       "  'ND': 0.001999800019998,\n",
       "  'NE': 0.00019998000199980003,\n",
       "  'NF': 0.0008332500083325001,\n",
       "  'NN': 0.9684364896843649,\n",
       "  'NR': 0.017198280171982803},\n",
       " 'RR': {'</s>': 0.02809862283429587,\n",
       "  'RA': 0.0021101732563305197,\n",
       "  'RD': 0.03327092720695564,\n",
       "  'RE': 0.006743034841657676,\n",
       "  'RF': 0.06482833026591356,\n",
       "  'RN': 0.45871676080472173,\n",
       "  'RR': 0.40623215079012504}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decoding on the test file -- Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Viterbi Algorithm Implementation\n",
    "## Dynamic Programming\n",
    "tag_list = ['<s>','EE', 'ND', 'DA', 'AF', 'EA', 'FN', 'NN', 'NE', '<s>E', 'DF', '<s>R', 'AD', 'AA', 'FA', '<s>D', 'FD', 'NF', '<s>F','RE','RD','EF','<s>N','RR','NR','NA','<s>A','DD','DE','AE','RA','DR','ED','DN','FE','AR','EN','FF','ER','RN','FR','RF','AN','</s>']\n",
    "\n",
    "count_correct_prediction = 0\n",
    "count_totalword = 0\n",
    "with open (\"C:/Users/Xin/Desktop/Github-repo/Natural_Language_Processing_Projects/Project_3_Sequence_Tagging/hw3-data/test.txt\") as test_file:\n",
    "    for line in test_file:\n",
    "        word_eachline = []\n",
    "        tag_eachline = []\n",
    "        tag_eachline.append(\"<s>\")\n",
    "        line_list = line.split()\n",
    "        for item in line_list:\n",
    "            temp = item.split('/')\n",
    "            word_eachline.append(temp[0])\n",
    "            tag_eachline.append(temp[1])\n",
    "        tag_eachline.append('</s>')\n",
    "        ## Use Viterbi Algorithm\n",
    "        ## Viterbi matrix is len(tag_list)*len(word_eachline)\n",
    "        viterbi = np.zeros((len(tag_list),len(word_eachline))) ## intialize the viterbi matrx all zeros \n",
    "        backpointer = np.zeros((len(tag_list),len(word_eachline)),dtype=int) ## intialize the backpointer matrx all zeros\n",
    "        for i in range(1, len(tag_list)-1): ## iterate all tag without start and stop tags\n",
    "            ## Get the entries for the first column in Viterbi matrix\n",
    "            if tag_list[i] in transition_matrix[\"<s>\"] and word_eachline[0] in emission_matrix[tag_list[i]]:\n",
    "                viterbi[i,0] = transition_matrix[\"<s>\"][tag_list[i]]*emission_matrix[tag_list[i]][word_eachline[0]]\n",
    "            \n",
    "            if tag_list[i] not in transition_matrix[\"<s>\"] and word_eachline[0] in emission_matrix[tag_list[i]]:\n",
    "                viterbi[i,0] = 0\n",
    "            \n",
    "            if tag_list[i] in transition_matrix[\"<s>\"] and word_eachline[0] not in emission_matrix[tag_list[i]]:\n",
    "                viterbi[i,0] = transition_matrix[\"<s>\"][tag_list[i]]*emission_matrix[tag_list[i]][\"unk\"]\n",
    "                \n",
    "            if tag_list[i] not in transition_matrix[\"<s>\"] and word_eachline[0] not in emission_matrix[tag_list[i]]:\n",
    "                viterbi[i,0] = 0\n",
    "                \n",
    "            backpointer[i,0] = 0 ## 0 means the previous tag is '<s>'\n",
    "            \n",
    "        ## Calculate other entries\n",
    "        for i in range(1,len(word_eachline)):\n",
    "            for j in range(1, len(tag_list)-1):\n",
    "                temp1 = []\n",
    "                temp2 = []\n",
    "                for k in range(1, len(tag_list)-1):\n",
    "                    if tag_list[j] in transition_matrix[tag_list[k]] and word_eachline[i] in emission_matrix[tag_list[j]]:\n",
    "                        temp1.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]]*emission_matrix[tag_list[j]][word_eachline[i]])\n",
    "                        temp2.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]])\n",
    "                    if tag_list[j] not in transition_matrix[tag_list[k]] and word_eachline[i] in emission_matrix[tag_list[j]]:\n",
    "                        temp1.append(0)\n",
    "                        temp2.append(0)\n",
    "                    if tag_list[j] in transition_matrix[tag_list[k]] and word_eachline[i] not in emission_matrix[tag_list[j]]:\n",
    "                        temp1.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]]*emission_matrix[tag_list[j]]['unk'])\n",
    "                        temp2.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]])\n",
    "                    if tag_list[j] not in transition_matrix[tag_list[k]] and word_eachline[i] not in emission_matrix[tag_list[j]]:\n",
    "                        temp1.append(0)\n",
    "                        temp2.append(0)\n",
    "                viterbi[j,i] = max(temp1)\n",
    "                backpointer[j,i]= temp2.index(max(temp2))+1  ## here if there are more than one largest values in temp2, the index function only get the smallest index\n",
    "                \n",
    "        ## Temination step\n",
    "        temp = []\n",
    "        for i in range(1, len(tag_list)-1):\n",
    "            if \"</s>\" in transition_matrix[tag_list[i]]:\n",
    "                temp.append(viterbi[i,-1]*transition_matrix[tag_list[i]]['</s>'])\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        viterbi[tag_list.index(\"</s>\"),-1] = max(temp)\n",
    "        backpointer[tag_list.index(\"</s>\"),-1] = temp.index(max(temp))+1\n",
    "        \n",
    "        ## Backtrack to get the tag sequence\n",
    "        predict_eachline = [\"</s>\"]\n",
    "        predict_eachline.append(tag_list[backpointer[-1,-1]])\n",
    "        prev = backpointer[-1,-1]\n",
    "\n",
    "        for i in range(len(word_eachline)-1, 0, -1):\n",
    "            predict_eachline.append(tag_list[backpointer[prev,i]])\n",
    "            prev = backpointer[prev,i]\n",
    "        predict_eachline.append(tag_list[backpointer[prev,0]])\n",
    "        predict_eachline = predict_eachline[::-1]\n",
    "        \n",
    "        predict_eachline_transform_back_unitag = [\"<s>\"]\n",
    "        \n",
    "        for i in range(1,len(predict_eachline)-1):\n",
    "            predict_eachline_transform_back_unitag.append(predict_eachline[i][-1])\n",
    "        \n",
    "        predict_eachline_transform_back_unitag.append('</s>')\n",
    "            \n",
    "        \n",
    "        ## Count the correct prediction, not count the start and stop tags\n",
    "        for i in range(1,len(predict_eachline_transform_back_unitag)-1):\n",
    "            count_totalword += 1\n",
    "            if predict_eachline_transform_back_unitag[i] == tag_eachline[i]:\n",
    "                count_correct_prediction += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy by trigram hidden Markov model is : 0.920294416944066.\n"
     ]
    }
   ],
   "source": [
    "print (\"The prediction accuracy by trigram hidden Markov model is : {}.\".format(count_correct_prediction/count_totalword))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction on the second line of text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_list = ['<s>','EE', 'ND', 'DA', 'AF', 'EA', 'FN', 'NN', 'NE', '<s>E', 'DF', '<s>R', 'AD', 'AA', 'FA', '<s>D', 'FD', 'NF', '<s>F','RE','RD','EF','<s>N','RR','NR','NA','<s>A','DD','DE','AE','RA','DR','ED','DN','FE','AR','EN','FF','ER','RN','FR','RF','AN','</s>']\n",
    "\n",
    "count_correct_prediction = 0\n",
    "count_totalword = 0\n",
    "with open (\"C:/Users/Xin/Desktop/Github-repo/Natural_Language_Processing_Projects/Project_3_Sequence_Tagging/hw3-data/test.txt\") as test_file:\n",
    "    first_line = next(test_file)\n",
    "    second_line = next(test_file)\n",
    "    word_eachline = []\n",
    "    tag_eachline = []\n",
    "    tag_eachline.append(\"<s>\")\n",
    "    line_list = second_line.split()\n",
    "    for item in line_list:\n",
    "        temp = item.split('/')\n",
    "        word_eachline.append(temp[0])\n",
    "        tag_eachline.append(temp[1])\n",
    "    tag_eachline.append('</s>')\n",
    "    ## Use Viterbi Algorithm\n",
    "    ## Viterbi matrix is len(tag_list)*len(word_eachline)\n",
    "    viterbi = np.zeros((len(tag_list),len(word_eachline))) ## intialize the viterbi matrx all zeros \n",
    "    backpointer = np.zeros((len(tag_list),len(word_eachline)),dtype=int) ## intialize the backpointer matrx all zeros\n",
    "    for i in range(1, len(tag_list)-1): ## iterate all tag without start and stop tags\n",
    "        ## Get the entries for the first column in Viterbi matrix\n",
    "        if tag_list[i] in transition_matrix[\"<s>\"] and word_eachline[0] in emission_matrix[tag_list[i]]:\n",
    "            viterbi[i,0] = transition_matrix[\"<s>\"][tag_list[i]]*emission_matrix[tag_list[i]][word_eachline[0]]\n",
    "            \n",
    "        if tag_list[i] not in transition_matrix[\"<s>\"] and word_eachline[0] in emission_matrix[tag_list[i]]:\n",
    "            viterbi[i,0] = 0\n",
    "            \n",
    "        if tag_list[i] in transition_matrix[\"<s>\"] and word_eachline[0] not in emission_matrix[tag_list[i]]:\n",
    "            viterbi[i,0] = transition_matrix[\"<s>\"][tag_list[i]]*emission_matrix[tag_list[i]][\"unk\"]\n",
    "                \n",
    "        if tag_list[i] not in transition_matrix[\"<s>\"] and word_eachline[0] not in emission_matrix[tag_list[i]]:\n",
    "            viterbi[i,0] = 0\n",
    "                \n",
    "        backpointer[i,0] = 0 ## 0 means the previous tag is '<s>'\n",
    "            \n",
    "    ## Calculate other entries\n",
    "    for i in range(1,len(word_eachline)):\n",
    "        for j in range(1, len(tag_list)-1):\n",
    "            temp1 = []\n",
    "            temp2 = []\n",
    "            for k in range(1, len(tag_list)-1):\n",
    "                if tag_list[j] in transition_matrix[tag_list[k]] and word_eachline[i] in emission_matrix[tag_list[j]]:\n",
    "                    temp1.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]]*emission_matrix[tag_list[j]][word_eachline[i]])\n",
    "                    temp2.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]])\n",
    "                if tag_list[j] not in transition_matrix[tag_list[k]] and word_eachline[i] in emission_matrix[tag_list[j]]:\n",
    "                    temp1.append(0)\n",
    "                    temp2.append(0)\n",
    "                if tag_list[j] in transition_matrix[tag_list[k]] and word_eachline[i] not in emission_matrix[tag_list[j]]:\n",
    "                    temp1.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]]*emission_matrix[tag_list[j]]['unk'])\n",
    "                    temp2.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]])\n",
    "                if tag_list[j] not in transition_matrix[tag_list[k]] and word_eachline[i] not in emission_matrix[tag_list[j]]:\n",
    "                    temp1.append(0)\n",
    "                    temp2.append(0)\n",
    "            viterbi[j,i] = max(temp1)\n",
    "            backpointer[j,i]= temp2.index(max(temp2))+1  ## here if there are more than one largest values in temp2, the index function only get the smallest index\n",
    "                \n",
    "    ## Temination step\n",
    "    temp = []\n",
    "    for i in range(1, len(tag_list)-1):\n",
    "        if \"</s>\" in transition_matrix[tag_list[i]]:\n",
    "            temp.append(viterbi[i,-1]*transition_matrix[tag_list[i]]['</s>'])\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    viterbi[tag_list.index(\"</s>\"),-1] = max(temp)\n",
    "    backpointer[tag_list.index(\"</s>\"),-1] = temp.index(max(temp))+1\n",
    "        \n",
    "    ## Backtrack to get the tag sequence\n",
    "    predict_eachline = [\"</s>\"]\n",
    "    predict_eachline.append(tag_list[backpointer[-1,-1]])\n",
    "    prev = backpointer[-1,-1]\n",
    "\n",
    "    for i in range(len(word_eachline)-1, 0, -1):\n",
    "        predict_eachline.append(tag_list[backpointer[prev,i]])\n",
    "        prev = backpointer[prev,i]\n",
    "    predict_eachline.append(tag_list[backpointer[prev,0]])\n",
    "    predict_eachline = predict_eachline[::-1]\n",
    "    \n",
    "    ## Transform the predictd tag back to the unitag form\n",
    "    predict_eachline_transform_back_unitag = [\"<s>\"]        \n",
    "    for i in range(1,len(predict_eachline)-1):\n",
    "        predict_eachline_transform_back_unitag.append(predict_eachline[i][-1])        \n",
    "    predict_eachline_transform_back_unitag.append('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction on the second line of test file is: ['<s>', 'F', 'F', 'D', 'D', 'F', 'F', 'D', 'D', 'D', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'F', 'F', '</s>'].\n"
     ]
    }
   ],
   "source": [
    "print(\"The prediction on the second line of test file is: {}.\".format(predict_eachline_transform_back_unitag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'guess', \"it's\", 'pretty', 'deep', 'feelings', ',']\n"
     ]
    }
   ],
   "source": [
    "## Print out the 2nd line which only contains the word labeled as N \n",
    "output_label_N = []\n",
    "for i in range(1,len(predict_eachline_transform_back_unitag)-1):\n",
    "    if predict_eachline_transform_back_unitag[i] == 'N':\n",
    "        output_label_N.append(word_eachline[i-1])\n",
    "print (output_label_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
