{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Construct the emission matrix p(w/t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Construct bag of word for word and tag seperately\n",
    "word_count = {}\n",
    "tag_count = {}\n",
    "with open (\"C:/Users/Xin/Desktop/Github-repo/Natural_Language_Processing_Projects/Project_3_Sequence_Tagging/hw3-data/train.txt\") as train_file:\n",
    "    for line in train_file:\n",
    "        line_list = line.split()\n",
    "        for i in range(len(line_list)):\n",
    "            temp = line_list[i].split('/')\n",
    "            if temp[0] not in word_count:\n",
    "                word_count[temp[0]]=1\n",
    "            if temp[0] in word_count:\n",
    "                word_count[temp[0]]+=1\n",
    "            if temp[1] not in tag_count:\n",
    "                tag_count[temp[1]]=1\n",
    "            if temp[1] in tag_count:\n",
    "                tag_count[temp[1]]+=1\n",
    "\n",
    "#word_count = {}\n",
    "#{'spoke': 6,\n",
    "# 'finished': 53,\n",
    "# 'sucker': 5,\n",
    "# ...\n",
    "# ...\n",
    "\n",
    "#tag_count = {}\n",
    "# {'A': 3031, 'D': 65382, 'E': 8625, 'F': 78056, 'N': 1333610, 'R': 101735}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Construct the tree structure to store the c(t,w). \n",
    "# Use the dictionary to store the counts\n",
    "# For the dictionary word_tag_pair_counts, the keys are the tags in the training set, the value is a dictionary, in which the keys \n",
    "# are the words, the the value are the counts for this word-key pair \n",
    "tag_word_pair_counts = {}\n",
    "with open (\"C:/Users/Xin/Desktop/Github-repo/Natural_Language_Processing_Projects/Project_3_Sequence_Tagging/hw3-data/train.txt\") as train_file:\n",
    "    for line in train_file:\n",
    "        line_list = line.split()\n",
    "        for i in range(len(line_list)):\n",
    "            temp = line_list[i].split('/')\n",
    "            if temp[1] not in tag_word_pair_counts:\n",
    "                tag_word_pair_counts[temp[1]] = {}\n",
    "                tag_word_pair_counts[temp[1]][temp[0]] = 1\n",
    "            else:\n",
    "                if temp[0] not in tag_word_pair_counts[temp[1]]:\n",
    "                    tag_word_pair_counts[temp[1]][temp[0]] = 1\n",
    "                else:\n",
    "                    tag_word_pair_counts[temp[1]][temp[0]] += 1 \n",
    "#tag_word_pair_counts\n",
    "#{'A': {',': 389,\n",
    "#  '--': 17,\n",
    "#  '.': 40,\n",
    "#  '?': 7,\n",
    "#  '[inaudible]': 2,\n",
    "#  'a': 61,\n",
    "#  ...\n",
    "#  ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Construct the emission matrix, each entry is p(w/t), I use add one smoothing to deal with unknown word\n",
    "\n",
    "## I use a dictionary of dictionary to represent this matrix\n",
    "## The key of the outer dictionary is the tag, and the the key of the sub-dictionary is their corresponding word\n",
    "emission_matrix = {}\n",
    "delta = 0.1\n",
    "V = len(word_count) + 1 ## assum only one kind of unseen words\n",
    "for tag in tag_count:\n",
    "    emission_matrix[tag]={}\n",
    "    sum_tag_allword = 0\n",
    "    for word in tag_word_pair_counts[tag]:\n",
    "        sum_tag_allword += tag_word_pair_counts[tag][word]\n",
    "    sum_tag_allword += V*delta ## Add one smoothing\n",
    "    for word in tag_word_pair_counts[tag]:\n",
    "        emission_matrix[tag][word] = (tag_word_pair_counts[tag][word]+delta)/sum_tag_allword\n",
    "    emission_matrix[tag]['unk'] = delta/sum_tag_allword\n",
    "\n",
    "# emission_matrix\n",
    "#{'A': {',': 0.12838283828382838,\n",
    "#  '--': 0.005610561056105611,\n",
    "#  '.': 0.013201320132013201,\n",
    "#  '?': 0.0023102310231023103,\n",
    "#  '[inaudible]': 0.0006600660066006601,\n",
    "#  ....\n",
    "#  ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(you/A): 0.005543499704083646\n",
      "p(you/D): 0.2132616434292495\n",
      "p(you/E): 0.0007596361249179405\n",
      "p(you/F): 1.3733862711314207e-05\n",
      "p(you/N): 0.012937615299839477\n",
      "p(you/R): 0.012692126082892467\n"
     ]
    }
   ],
   "source": [
    "## Obtain p(you/t)\n",
    "print (\"p(you/A): {}\".format(emission_matrix['A']['you']))\n",
    "print (\"p(you/D): {}\".format(emission_matrix['D']['you']))\n",
    "print (\"p(you/E): {}\".format(emission_matrix['E']['you']))\n",
    "print (\"p(you/F): {}\".format(emission_matrix['F']['you']))\n",
    "print (\"p(you/N): {}\".format(emission_matrix['N']['you']))\n",
    "print (\"p(you/R): {}\".format(emission_matrix['R']['you']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construct transtion matrix p(t'/t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Considering the start and stop tag, there are 8 different tags ['A', 'D', 'E', 'F', 'N', 'R', <s>, </s>]\n",
    "## t =  ['A', 'D', 'E', 'F', 'N', 'R', <s>]\n",
    "## t' = ['A', 'D', 'E', 'F', 'N', 'R', </s>]\n",
    "\n",
    "## Construct a matrix to store the counts of c(t',t) \n",
    "## I use a dictionary of dictionary to represent this matrix\n",
    "## The key of the outer dictionary is t, and the the key of the sub-dictionary is t'\n",
    "\n",
    "tag_tag_count = {}\n",
    "with open (\"C:/Users/Xin/Desktop/Github-repo/Natural_Language_Processing_Projects/Project_3_Sequence_Tagging/hw3-data/train.txt\") as train_file:\n",
    "    for line in train_file:\n",
    "        line_list = line.split()\n",
    "        temp_tag_list = []\n",
    "        temp_tag_list.append(\"<s>\")\n",
    "        for i in range(len(line_list)):\n",
    "            temp = line_list[i].split('/')\n",
    "            temp_tag_list.append(temp[1])\n",
    "        temp_tag_list.append(\"</s>\")\n",
    "        for i in range(len(temp_tag_list)-1): ## i go through all the t in one sentence\n",
    "            if temp_tag_list[i] not in tag_tag_count:\n",
    "                tag_tag_count[temp_tag_list[i]]={}\n",
    "                tag_tag_count[temp_tag_list[i]][temp_tag_list[i+1]]=1\n",
    "            else:\n",
    "                if temp_tag_list[i+1] not in tag_tag_count[temp_tag_list[i]]:\n",
    "                    tag_tag_count[temp_tag_list[i]][temp_tag_list[i+1]]=1\n",
    "                else:\n",
    "                    tag_tag_count[temp_tag_list[i]][temp_tag_list[i+1]]+=1\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s>': {'A': 28, 'D': 11005, 'E': 1978, 'F': 12612, 'N': 153233, 'R': 11318},\n",
       " 'A': {'</s>': 46, 'A': 2564, 'D': 19, 'E': 2, 'F': 46, 'N': 305, 'R': 48},\n",
       " 'D': {'</s>': 4751,\n",
       "  'A': 38,\n",
       "  'D': 38134,\n",
       "  'E': 114,\n",
       "  'F': 736,\n",
       "  'N': 18923,\n",
       "  'R': 2685},\n",
       " 'E': {'</s>': 186, 'A': 1, 'D': 142, 'E': 5354, 'F': 64, 'N': 2378, 'R': 499},\n",
       " 'F': {'</s>': 6014,\n",
       "  'A': 89,\n",
       "  'D': 1999,\n",
       "  'E': 83,\n",
       "  'F': 39789,\n",
       "  'N': 27764,\n",
       "  'R': 2317},\n",
       " 'N': {'</s>': 177367,\n",
       "  'A': 174,\n",
       "  'D': 11910,\n",
       "  'E': 653,\n",
       "  'F': 20663,\n",
       "  'N': 1101003,\n",
       "  'R': 21839},\n",
       " 'R': {'</s>': 1810,\n",
       "  'A': 136,\n",
       "  'D': 2172,\n",
       "  'E': 440,\n",
       "  'F': 4145,\n",
       "  'N': 30003,\n",
       "  'R': 63028}}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Construct transition matrix\n",
    "## Construct the transition matrix to store the p(t'/t). The data structure is the same as that store c(t',t)\n",
    "transition_matrix = {}\n",
    "for tag in tag_tag_count:\n",
    "    transition_matrix[tag] = {}\n",
    "    sum_temp = 0\n",
    "    for taggg in tag_tag_count[tag]:\n",
    "        sum_temp += tag_tag_count[tag][taggg]\n",
    "    for taggg in tag_tag_count[tag]:\n",
    "        transition_matrix[tag][taggg] = tag_tag_count[tag][taggg]/sum_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s>': {'A': 0.0001472335860843228,\n",
       "  'D': 0.05786805767349901,\n",
       "  'E': 0.010401001188385373,\n",
       "  'F': 0.0663182138462671,\n",
       "  'N': 0.8057515748735369,\n",
       "  'R': 0.05951391883222733},\n",
       " 'A': {'</s>': 0.015181518151815182,\n",
       "  'A': 0.8462046204620463,\n",
       "  'D': 0.006270627062706271,\n",
       "  'E': 0.0006600660066006601,\n",
       "  'F': 0.015181518151815182,\n",
       "  'N': 0.10066006600660066,\n",
       "  'R': 0.015841584158415842},\n",
       " 'D': {'</s>': 0.07266637096404154,\n",
       "  'A': 0.0005812086080053838,\n",
       "  'D': 0.5832581330967712,\n",
       "  'E': 0.0017436258240161515,\n",
       "  'F': 0.011257093039262171,\n",
       "  'N': 0.2894265918233126,\n",
       "  'R': 0.041066976644590934},\n",
       " 'E': {'</s>': 0.021567717996289426,\n",
       "  'A': 0.00011595547309833024,\n",
       "  'D': 0.016465677179962893,\n",
       "  'E': 0.6208256029684601,\n",
       "  'F': 0.0074211502782931356,\n",
       "  'N': 0.2757421150278293,\n",
       "  'R': 0.05786178107606679},\n",
       " 'F': {'</s>': 0.077048235218756,\n",
       "  'A': 0.001140221638588175,\n",
       "  'D': 0.025610146691435527,\n",
       "  'E': 0.0010633527640766126,\n",
       "  'F': 0.5097559413234258,\n",
       "  'N': 0.3556979053231696,\n",
       "  'R': 0.02968419704054833},\n",
       " 'N': {'</s>': 0.13299775271462624,\n",
       "  'A': 0.00013047302470214282,\n",
       "  'D': 0.008930653587370812,\n",
       "  'E': 0.0004896487651178119,\n",
       "  'F': 0.015494046605864238,\n",
       "  'N': 0.8255815610122608,\n",
       "  'R': 0.01637586429005803},\n",
       " 'R': {'</s>': 0.017791495468574912,\n",
       "  'A': 0.0013368195490199933,\n",
       "  'D': 0.021349794562289894,\n",
       "  'E': 0.004325004423299979,\n",
       "  'F': 0.040743507578587294,\n",
       "  'N': 0.29491615389152104,\n",
       "  'R': 0.6195372245267069}}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decoding on the test file -- Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Viterbi Algorithm Implementation\n",
    "## Dynamic Programming\n",
    "\n",
    "tag_list = ['<s>', 'A', 'D', 'E', 'F', 'N', 'R', '</s>']\n",
    "count_correct_prediction = 0\n",
    "count_totalword = 0\n",
    "with open (\"C:/Users/Xin/Desktop/Github-repo/Natural_Language_Processing_Projects/Project_3_Sequence_Tagging/hw3-data/test.txt\") as test_file:\n",
    "    for line in test_file:\n",
    "        word_eachline = []\n",
    "        tag_eachline = []\n",
    "        tag_eachline.append(\"<s>\")\n",
    "        line_list = line.split()\n",
    "        for item in line_list:\n",
    "            temp = item.split('/')\n",
    "            word_eachline.append(temp[0])\n",
    "            tag_eachline.append(temp[1])\n",
    "        tag_eachline.append('</s>')\n",
    "        ## Use Viterbi Algorithm\n",
    "        ## Viterbi matrix is len(tag_list)*len(word_eachline)\n",
    "        viterbi = np.zeros((len(tag_list),len(word_eachline))) ## intialize the viterbi matrx all ones \n",
    "        backpointer = np.zeros((len(tag_list),len(word_eachline)),dtype=int)\n",
    "        for i in range(1, len(tag_list)-1):\n",
    "            ## Get the entries for the first column in Viterbi matrix\n",
    "            if tag_list[i] in transition_matrix[\"<s>\"] and word_eachline[0] in emission_matrix[tag_list[i]]:\n",
    "                viterbi[i,0] = transition_matrix[\"<s>\"][tag_list[i]]*emission_matrix[tag_list[i]][word_eachline[0]]\n",
    "            \n",
    "            if tag_list[i] not in transition_matrix[\"<s>\"] and word_eachline[0] in emission_matrix[tag_list[i]]:\n",
    "                viterbi[i,0] = 0\n",
    "            \n",
    "            if tag_list[i] in transition_matrix[\"<s>\"] and word_eachline[0] not in emission_matrix[tag_list[i]]:\n",
    "                viterbi[i,0] = transition_matrix[\"<s>\"][tag_list[i]]*emission_matrix[tag_list[i]][\"unk\"]\n",
    "                \n",
    "            if tag_list[i] not in transition_matrix[\"<s>\"] and word_eachline[0] not in emission_matrix[tag_list[i]]:\n",
    "                viterbi[i,0] = 0\n",
    "                \n",
    "            backpointer[i,0] = 0 ## 0 means the previous tag is '<s>'\n",
    "            \n",
    "        ## Calculate other entries\n",
    "        for i in range(1,len(word_eachline)):\n",
    "            for j in range(1, len(tag_list)-1):\n",
    "                temp1 = []\n",
    "                temp2 = []\n",
    "                for k in range(1, len(tag_list)-1):\n",
    "                    if tag_list[j] in transition_matrix[tag_list[k]] and word_eachline[i] in emission_matrix[tag_list[j]]:\n",
    "                        temp1.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]]*emission_matrix[tag_list[j]][word_eachline[i]])\n",
    "                        temp2.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]])\n",
    "                    if tag_list[j] not in transition_matrix[tag_list[k]] and word_eachline[i] in emission_matrix[tag_list[j]]:\n",
    "                        temp1.append(0)\n",
    "                        temp2.append(0)\n",
    "                    if tag_list[j] in transition_matrix[tag_list[k]] and word_eachline[i] not in emission_matrix[tag_list[j]]:\n",
    "                        temp1.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]]*emission_matrix[tag_list[j]]['unk'])\n",
    "                        temp2.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]])\n",
    "                    if tag_list[j] not in transition_matrix[tag_list[k]] and word_eachline[i] not in emission_matrix[tag_list[j]]:\n",
    "                        temp1.append(0)\n",
    "                        temp2.append(0)\n",
    "                viterbi[j,i] = max(temp1)\n",
    "                backpointer[j,i]= temp2.index(max(temp2))+1  ## here if there are more than one largest values in temp2, the index function only get the smallest index\n",
    "                \n",
    "        ## Temination step\n",
    "        temp = []\n",
    "        for i in range(1, len(tag_list)-1):\n",
    "            if \"</s>\" in transition_matrix[tag_list[i]]:\n",
    "                temp.append(viterbi[i,-1]*transition_matrix[tag_list[i]]['</s>'])\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        viterbi[tag_list.index(\"</s>\"),-1] = max(temp)\n",
    "        backpointer[tag_list.index(\"</s>\"),-1] = temp.index(max(temp))+1\n",
    "        \n",
    "        ## Backtrack to get the tag sequence\n",
    "        predict_eachline = [\"</s>\"]\n",
    "        predict_eachline.append(tag_list[backpointer[-1,-1]])\n",
    "        prev = backpointer[-1,-1]\n",
    "\n",
    "        for i in range(len(word_eachline)-1, 0, -1):\n",
    "            predict_eachline.append(tag_list[backpointer[prev,i]])\n",
    "            prev = backpointer[prev,i]\n",
    "        predict_eachline.append(tag_list[backpointer[prev,0]])\n",
    "        predict_eachline = predict_eachline[::-1]\n",
    "        \n",
    "        ## Count the correct prediction\n",
    "        for i in range(1,len(predict_eachline)-1):\n",
    "            count_totalword += 1\n",
    "            if predict_eachline[i] == tag_eachline[i]:\n",
    "                count_correct_prediction += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy by bigram hidden Markov model is : 0.8898264889011539.\n"
     ]
    }
   ],
   "source": [
    "print (\"The prediction accuracy by bigram hidden Markov model is : {}.\".format(count_correct_prediction/count_totalword))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction on the second line of text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_list = ['<s>', 'A', 'D', 'E', 'F', 'N', 'R', '</s>']\n",
    "with open (\"C:/Users/Xin/Desktop/Github-repo/Natural_Language_Processing_Projects/Project_3_Sequence_Tagging/hw3-data/test.txt\") as test_file:\n",
    "    line = next(test_file)\n",
    "    line = next(test_file)\n",
    "    word_eachline = []\n",
    "    tag_eachline = []\n",
    "    tag_eachline.append(\"<s>\")\n",
    "    line_list = line.split()\n",
    "    for item in line_list:\n",
    "        temp = item.split('/')\n",
    "        word_eachline.append(temp[0])\n",
    "        tag_eachline.append(temp[1])\n",
    "    tag_eachline.append('</s>')\n",
    "        ## Use Viterbi Algorithm\n",
    "        ## Viterbi matrix is len(tag_list)*len(word_eachline)\n",
    "    viterbi = np.zeros((len(tag_list),len(word_eachline))) ## intialize the viterbi matrx all ones \n",
    "    backpointer = np.zeros((len(tag_list),len(word_eachline)),dtype=int)\n",
    "    for i in range(1, len(tag_list)-1):\n",
    "            ## Get the entries for the first column in Viterbi matrix\n",
    "        if tag_list[i] in transition_matrix[\"<s>\"] and word_eachline[0] in emission_matrix[tag_list[i]]:\n",
    "            viterbi[i,0] = transition_matrix[\"<s>\"][tag_list[i]]*emission_matrix[tag_list[i]][word_eachline[0]]\n",
    "            \n",
    "        if tag_list[i] not in transition_matrix[\"<s>\"] and word_eachline[0] in emission_matrix[tag_list[i]]:\n",
    "            viterbi[i,0] = 0\n",
    "            \n",
    "        if tag_list[i] in transition_matrix[\"<s>\"] and word_eachline[0] not in emission_matrix[tag_list[i]]:\n",
    "            viterbi[i,0] = transition_matrix[\"<s>\"][tag_list[i]]*emission_matrix[tag_list[i]][\"unk\"]\n",
    "                \n",
    "        if tag_list[i] not in transition_matrix[\"<s>\"] and word_eachline[0] not in emission_matrix[tag_list[i]]:\n",
    "            viterbi[i,0] = 0\n",
    "                \n",
    "        backpointer[i,0] = 0 ## 0 means the previous tag is '<s>'\n",
    "            \n",
    "        ## Calculate other entries\n",
    "    for i in range(1,len(word_eachline)):\n",
    "        for j in range(1, len(tag_list)-1):\n",
    "            temp1 = []\n",
    "            temp2 = []\n",
    "            for k in range(1, len(tag_list)-1):\n",
    "                if tag_list[j] in transition_matrix[tag_list[k]] and word_eachline[i] in emission_matrix[tag_list[j]]:\n",
    "                    temp1.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]]*emission_matrix[tag_list[j]][word_eachline[i]])\n",
    "                    temp2.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]])\n",
    "                if tag_list[j] not in transition_matrix[tag_list[k]] and word_eachline[i] in emission_matrix[tag_list[j]]:\n",
    "                    temp1.append(0)\n",
    "                    temp2.append(0)\n",
    "                if tag_list[j] in transition_matrix[tag_list[k]] and word_eachline[i] not in emission_matrix[tag_list[j]]:\n",
    "                    temp1.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]]*emission_matrix[tag_list[j]]['unk'])\n",
    "                    temp2.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]])\n",
    "                if tag_list[j] not in transition_matrix[tag_list[k]] and word_eachline[i] not in emission_matrix[tag_list[j]]:\n",
    "                    temp1.append(0)\n",
    "                    temp2.append(0)\n",
    "            viterbi[j,i] = max(temp1)\n",
    "            backpointer[j,i]= temp2.index(max(temp2))+1  ## here if there are more than one largest values in temp2, the index function only get the smallest index\n",
    "                \n",
    "        ## Temination step\n",
    "    temp = []\n",
    "    for i in range(1, len(tag_list)-1):\n",
    "        if \"</s>\" in transition_matrix[tag_list[i]]:\n",
    "            temp.append(viterbi[i,-1]*transition_matrix[tag_list[i]]['</s>'])\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    viterbi[tag_list.index(\"</s>\"),-1] = max(temp)\n",
    "    backpointer[tag_list.index(\"</s>\"),-1] = temp.index(max(temp))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.90458840e-09   4.83450480e-08   6.07309950e-11   1.88948169e-11\n",
      "    8.92130265e-16   7.94645322e-15   1.33573023e-16   9.83355264e-19\n",
      "    6.39691771e-19   4.86577352e-20   1.14531277e-22   5.18139255e-25\n",
      "    9.51463828e-29   1.58834699e-33   2.65154184e-38   1.72231592e-39\n",
      "    3.16270440e-43   9.91168711e-42]\n",
      " [  2.66079767e-06   4.45576069e-06   4.23517840e-07   7.78069742e-08\n",
      "    6.73117035e-14   7.32391327e-13   1.15417129e-13   1.43383701e-14\n",
      "    2.63418701e-15   1.16222131e-19   3.44717925e-24   4.30430213e-28\n",
      "    2.64713916e-29   2.17931156e-33   5.53642103e-38   2.76883333e-37\n",
      "    2.39534939e-43   9.13518707e-40]\n",
      " [  9.75429165e-08   1.20307929e-07   2.69241105e-11   1.51257916e-10\n",
      "    1.27230844e-15   1.97749588e-14   1.70697996e-17   1.52872430e-19\n",
      "    5.12089874e-18   1.29098656e-18   7.51643542e-24   1.49215352e-28\n",
      "    1.45712446e-30   7.55492366e-34   1.91928677e-38   9.87200416e-39\n",
      "    5.74771915e-44   2.46654952e-41]\n",
      " [  5.52361980e-04   1.28565403e-04   5.80958053e-09   2.17688760e-09\n",
      "    9.07914836e-11   2.11322359e-11   1.47945053e-16   2.06937191e-20\n",
      "    7.36994220e-17   5.15963619e-22   4.67757704e-25   6.28598191e-28\n",
      "    3.51442651e-30   3.18265600e-33   8.08536237e-38   6.96354609e-37\n",
      "    1.13245086e-37   2.63584399e-38]\n",
      " [  4.47020410e-05   1.61900025e-05   2.36963935e-08   1.01007116e-08\n",
      "    1.85463147e-14   2.66114324e-12   9.72480698e-14   3.10656085e-16\n",
      "    3.41963732e-16   2.36579269e-17   3.24943798e-20   1.81672667e-22\n",
      "    1.64522320e-25   4.17959898e-30   9.84300162e-35   6.69621473e-36\n",
      "    5.42211387e-41   3.31926942e-39]\n",
      " [  5.73500996e-08   6.36594756e-06   2.31833358e-10   6.75271489e-09\n",
      "    4.03145158e-15   1.04636786e-12   8.22784640e-15   5.11351976e-18\n",
      "    2.28615931e-16   9.19522834e-18   3.40907968e-21   3.59243982e-23\n",
      "    1.07450950e-26   7.05644530e-32   6.59560248e-38   6.25814700e-37\n",
      "    3.73618863e-43   1.30514464e-39]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.03087128e-39]]\n"
     ]
    }
   ],
   "source": [
    "print (viterbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 4 4 2 2 4 4 1 2 2 1 1 1 1 1 1 1 4]\n",
      " [0 4 4 2 2 4 4 2 2 2 5 5 5 5 5 5 2 4]\n",
      " [0 4 4 2 2 4 4 2 2 2 3 5 6 5 5 5 3 4]\n",
      " [0 4 4 2 4 4 4 5 2 4 6 5 5 5 5 5 4 4]\n",
      " [0 4 4 2 2 4 4 5 2 2 5 5 5 5 5 5 5 4]\n",
      " [0 4 6 2 6 4 6 6 2 6 6 6 6 6 5 5 6 4]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "print(backpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_2ndline = [\"</s>\"]\n",
    "pred_2ndline.append(tag_list[backpointer[-1,-1]])\n",
    "prev = backpointer[-1,-1]\n",
    "\n",
    "for i in range (len(word_eachline)-1, 0, -1):\n",
    "    pred_2ndline.append(tag_list[backpointer[prev,i]])\n",
    "    prev = backpointer[prev,i]\n",
    "pred_2ndline.append(tag_list[backpointer[prev,0]])\n",
    "pred_2ndline = pred_2ndline[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction on the second line of test file is: ['<s>', 'F', 'F', 'D', 'F', 'F', 'F', 'D', 'D', 'D', 'N', 'N', 'N', 'N', 'N', 'N', 'F', 'F', 'F', '</s>'].\n"
     ]
    }
   ],
   "source": [
    "print(\"The prediction on the second line of test file is: {}.\".format(pred_2ndline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log probability of this model output is: -89.09235372457093.\n"
     ]
    }
   ],
   "source": [
    "print(\"The log probability of this model output is: {}.\".format(np.log(viterbi[-1,-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "pred.append(tag_list[backpointer[-1,-1]])\n",
    "prev = backpointer[-1,-1]\n",
    "\n",
    "for i in range (len(word_eachline)-1, 0, -1):\n",
    "    pred.append(tag_list[backpointer[prev,i]])\n",
    "    prev = backpointer[prev,i]\n",
    "pred = pred[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'F', 'D', 'F', 'F', 'F', 'D', 'D', 'D', 'N', 'N', 'N', 'N', 'N', 'N', 'F', 'F', 'F']\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'guess', \"it's\", 'pretty', 'deep', 'feelings']\n"
     ]
    }
   ],
   "source": [
    "output_label_N = []\n",
    "for i in range(1,len(pred_2ndline)-1):\n",
    "    if pred_2ndline[i] == 'N':\n",
    "        output_label_N.append(word_eachline[i-1])\n",
    "print (output_label_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
