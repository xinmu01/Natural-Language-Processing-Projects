{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import autograd.numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import operator\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### This code computes the counts c(k) and c(k,w). I use dict to store the counts for class and word\n",
    "\n",
    "stemmer = nltk.wordnet.WordNetLemmatizer() \n",
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "class_count = {} ## a dict to store c(k)\n",
    "class_word_count = {} ## a dict to store c(k,w)\n",
    "with open ('C:/Users/Xin/Desktop/NLP/Homework1/hw1-data/train') as f_train:\n",
    "    for line in f_train:\n",
    "        ## remove all the punctuations and stopwords\n",
    "        line_lt = [w for w in line.split() if w not in string.punctuation if w not in stop_words] \n",
    "        ## remove the affixes\n",
    "        line_list = []\n",
    "        line_list.append(line_lt[0])\n",
    "        for item in line_lt[1:]:\n",
    "            line_list.append(stemmer.lemmatize(item))   ## use Wordnet Stemmer to remove affix\n",
    "        ## Now line_list is a list containing all the words in one document\n",
    "        \n",
    "        ## Calculate the c(k)\n",
    "        if line_list[0] not in class_count :\n",
    "            class_count [line_list[0]] = 1\n",
    "        else:\n",
    "            class_count[line_list[0]] += 1\n",
    "        \n",
    "        ## Calculate the c(k,w)\n",
    "        if line_list[0] not in class_word_count:\n",
    "            class_word_count[line_list[0]]={}\n",
    "            for w in line_list[1:]:\n",
    "                if w not in class_word_count[line_list[0]]:\n",
    "                    class_word_count[line_list[0]][w] = 1\n",
    "                else: \n",
    "                    class_word_count[line_list[0]][w] += 1\n",
    "        else:\n",
    "            for w in line_list[1:]:\n",
    "                if w not in class_word_count[line_list[0]]:\n",
    "                    class_word_count[line_list[0]][w] = 1\n",
    "                else: \n",
    "                    class_word_count[line_list[0]][w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c(trump): 637 \n",
      "c(clinton): 455\n",
      "c(trump, president): 41\n",
      "c(trump,country): 174\n",
      "c(clinton,president): 187\n",
      "c(clinton,country): 174\n"
     ]
    }
   ],
   "source": [
    "### Counts for Trump and Clinton for words country and president\n",
    "c_trump = class_count['trump']\n",
    "c_clinton = class_count['clinton']\n",
    "c_trump_president = class_word_count['trump']['president']\n",
    "c_trump_country = class_word_count['trump']['country']\n",
    "c_clinton_president = class_word_count['clinton']['president']\n",
    "c_clinton_country = class_word_count['trump']['country']\n",
    "\n",
    "print(\"c(trump): {} \".format(c_trump))\n",
    "print (\"c(clinton): {}\".format(c_clinton))\n",
    "print (\"c(trump, president): {}\".format(c_trump_president))\n",
    "print (\"c(trump,country): {}\".format(c_trump_country))\n",
    "print (\"c(clinton,president): {}\".format(c_clinton_president))\n",
    "print (\"c(clinton,country): {}\".format(c_clinton_country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Calculate the probability of each class p(k)\n",
    "total_count = 0\n",
    "for i in class_count:\n",
    "    total_count = total_count + class_count[i]\n",
    "\n",
    "class_prob = {} ## p(k) stores in this dict\n",
    "\n",
    "for i in class_count:\n",
    "    class_prob[i]=class_count[i]/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(trump): 0.20183776932826364\n",
      "p(clinton): 0.14416983523447402\n"
     ]
    }
   ],
   "source": [
    "## Probability of trump and clinton\n",
    "p_trump = class_prob['trump']\n",
    "p_clinton = class_prob['clinton']\n",
    "\n",
    "print (\"p(trump): {}\".format(p_trump))\n",
    "print (\"p(clinton): {}\".format(p_clinton))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Calculate the probability p(w|k) with add-one smoothing\n",
    "\n",
    "## Calculate the V\n",
    "all_word_seen = []\n",
    "for i in class_word_count:\n",
    "    for j in class_word_count[i]:\n",
    "        all_word_seen.append(j)\n",
    "all_word_seen = set(all_word_seen)\n",
    "size_seenword = len(all_word_seen)\n",
    "V=size_seenword + 1\n",
    "        \n",
    "## Claculate p(w|k) \n",
    "\n",
    "class_word_prob = {} ##Stores p(w|k)\n",
    "total_word_eachclass = {}\n",
    "\n",
    "for i in class_word_count:\n",
    "    class_word_prob[i]={}\n",
    "    total_word_eachclass[i] = 0\n",
    "    for j in class_word_count[i]:\n",
    "        total_word_eachclass[i] = total_word_eachclass[i] + class_word_count[i][j]\n",
    "    for k in class_word_count[i]:\n",
    "        class_word_prob[i][k] = (class_word_count[i][k]+1)/(total_word_eachclass[i]+V)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(country|trump): 0.0073396804093444614\n",
      "p(president|trump): 0.0017615232982426709\n",
      "p(country|clinton): 0.003429218271407644\n",
      "p(president|clinton): 0.0062591556798508455\n"
     ]
    }
   ],
   "source": [
    "## Probability of trump and clinton for words country and president\n",
    "p_trump_country = class_word_prob['trump']['country']\n",
    "p_trump_president = class_word_prob['trump']['president']\n",
    "p_clinton_country = class_word_prob['clinton']['country']\n",
    "p_clinton_president = class_word_prob['clinton']['president']\n",
    "\n",
    "print (\"p(country|trump): {}\".format(p_trump_country))\n",
    "print (\"p(president|trump): {}\".format(p_trump_president))\n",
    "print (\"p(country|clinton): {}\".format(p_clinton_country))\n",
    "print (\"p(president|clinton): {}\".format(p_clinton_president))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(rubio|1st document in dev): 0.057742183296234026\n",
      "P(huckabee|1st document in dev): 1.0761957001997873e-14\n",
      "P(o'malley|1st document in dev): 6.591641421421866e-13\n",
      "P(fiorina|1st document in dev): 2.4586610838097202e-14\n",
      "P(clinton|1st document in dev): 0.9422377042069229\n",
      "P(chafee|1st document in dev): 1.547888366297945e-23\n",
      "P(paul|1st document in dev): 5.885568160330661e-10\n",
      "P(carson|1st document in dev): 1.690131764574655e-09\n",
      "P(webb|1st document in dev): 4.043591542783662e-14\n",
      "P(cruz|1st document in dev): 1.5314081325768036e-05\n",
      "P(trump|1st document in dev): 1.497867066347483e-07\n",
      "P(kasich|1st document in dev): 3.09320144671935e-08\n",
      "P(perry|1st document in dev): 3.2596431399191214e-28\n",
      "P(sanders|1st document in dev): 1.9505681907308288e-07\n",
      "P(walker|1st document in dev): 6.667568162998306e-13\n",
      "P(bush|1st document in dev): 4.4067383972904645e-06\n",
      "P(christie|1st document in dev): 1.3621489520720117e-08\n",
      "sum of all the probability: 1.0000000000000002\n",
      "predicted speaker: ['clinton']\n"
     ]
    }
   ],
   "source": [
    "## calculate the p(k/d) for the firtst document in dev file\n",
    "with open ('C:/Users/Xin/Desktop/NLP/Homework1/hw1-data/dev') as f_dev:\n",
    "    dev_1st_before_stemmer = [w for w in next(f_dev).split() if w not in string.punctuation if w not in stop_words]\n",
    "    dev_1st = []\n",
    "    dev_1st.append(dev_1st_before_stemmer[0])\n",
    "    for item in dev_1st_before_stemmer[1:]:\n",
    "        dev_1st.append(stemmer.lemmatize(item))\n",
    "\n",
    "## calculat P(k/d)\n",
    "    class_dev_1st_prob = {}\n",
    "    class_dev_1st_normalized_prob = {}\n",
    "    class_dev_1st_logprob = {}\n",
    "\n",
    "    for i in class_word_prob:\n",
    "        sum_log_pro_allword = 0\n",
    "        for j in dev_1st[1:]:\n",
    "            if j in class_word_prob[i]:\n",
    "                sum_log_pro_allword = sum_log_pro_allword + np.log(class_word_prob[i][j])\n",
    "            else:\n",
    "                sum_log_pro_allword = sum_log_pro_allword + np.log(1/(total_word_eachclass[i]+V))\n",
    "            \n",
    "        class_dev_1st_logprob[i]= np.log(class_prob[i])+sum_log_pro_allword\n",
    "    \n",
    "## Deal with the underflow problem\n",
    "## Before doing the np.exp() on log-prob, minus the largest log-prob for each class, then the largest log-prb is going to be 1\n",
    "\n",
    "largest_log_prob = max(class_dev_1st_logprob.values())\n",
    "\n",
    "for item in class_dev_1st_logprob:\n",
    "    class_dev_1st_prob[item] = np.exp(class_dev_1st_logprob[item]-largest_log_prob)\n",
    "\n",
    "total_prob = 0\n",
    "for item in class_dev_1st_prob:\n",
    "    total_prob = total_prob + class_dev_1st_prob[item]\n",
    "\n",
    "for item in class_dev_1st_prob:\n",
    "    class_dev_1st_normalized_prob[item] = class_dev_1st_prob[item]/total_prob\n",
    "\n",
    "## check whether the total probability summed to be 1\n",
    "\n",
    "total_normalized_prob = 0\n",
    "for item in class_dev_1st_normalized_prob:\n",
    "    print (\"P({}|1st document in dev): {}\".format(item,class_dev_1st_normalized_prob[item]))\n",
    "    total_normalized_prob = total_normalized_prob + class_dev_1st_normalized_prob[item]\n",
    "    \n",
    "print (\"sum of all the probability: {}\".format(total_normalized_prob))\n",
    "    \n",
    "predict_class = [key for key,val in class_dev_1st_normalized_prob.items() if val == max(class_dev_1st_normalized_prob.values())]\n",
    "print (\"predicted speaker: {}\".format(predict_class)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Function to predict the class\n",
    "def predict_class(doc):\n",
    "    class_prediction = {}\n",
    "    class_logprob = {}\n",
    "    for i in class_word_prob:\n",
    "        sum_log_pro_allword = 0\n",
    "        for j in doc[1:]:\n",
    "            if j in class_word_prob[i]:\n",
    "                sum_log_pro_allword = sum_log_pro_allword + np.log(class_word_prob[i][j])\n",
    "            else:\n",
    "                sum_log_pro_allword = sum_log_pro_allword + np.log(1/(total_word_eachclass[i]+V))\n",
    "        class_logprob[i] =np.log(class_prob[i])+sum_log_pro_allword   \n",
    "    \n",
    "    largest_log_prob = max(class_logprob.values())\n",
    "    \n",
    "    for i in class_logprob:\n",
    "        class_prediction[i]= np.exp(class_logprob[i]-largest_log_prob)        \n",
    "    \n",
    "    prediction = [key for key,val in class_prediction.items() if val == max(class_prediction.values())]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy on the dev file is 0.515\n"
     ]
    }
   ],
   "source": [
    "## Calculate the accuracy for dev file\n",
    "\n",
    "dev_prediction = []\n",
    "with open ('C:/Users/Xin/Desktop/NLP/Homework1/hw1-data/dev') as f_dev:\n",
    "    for doc in f_dev:\n",
    "        dev_doc_before_stemmer = [w for w in doc.split() if w not in string.punctuation if w not in stop_words]\n",
    "        \n",
    "        dev_doc = []\n",
    "        dev_doc.append(dev_doc_before_stemmer[0])\n",
    "        for item in dev_doc_before_stemmer[1:]:\n",
    "            dev_doc.append(stemmer.lemmatize(item))\n",
    "            \n",
    "        dev_doc_pred = {}\n",
    "        dev_doc_pred[dev_doc[0]] = predict_class(dev_doc)\n",
    "        dev_prediction.append(dev_doc_pred)\n",
    "\n",
    "count = 0 \n",
    "for i in dev_prediction:\n",
    "    for key, value in i.items():\n",
    "        if key == value[0]:\n",
    "            count +=1\n",
    "print ('Prediction accuracy on the dev file is {}' .format(count/len(dev_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy on the test file is 0.5375\n"
     ]
    }
   ],
   "source": [
    "## Calculate the accuracy for test file\n",
    "\n",
    "test_prediction = []\n",
    "with open ('C:/Users/Xin/Desktop/NLP/Homework1/hw1-data/test') as f_test:\n",
    "    for doc in f_test:\n",
    "        test_doc_before_stemmer = [w for w in doc.split() if w not in string.punctuation if w not in stop_words]\n",
    "        test_doc = []\n",
    "        test_doc.append(test_doc_before_stemmer[0])\n",
    "        for item in test_doc_before_stemmer[1:]:\n",
    "            test_doc.append(stemmer.lemmatize(item))\n",
    "        \n",
    "        test_doc_pred = {}\n",
    "        test_doc_pred[test_doc[0]] = predict_class(test_doc)\n",
    "        test_prediction.append(test_doc_pred)\n",
    "\n",
    "count = 0 \n",
    "for i in test_prediction:\n",
    "    for key, value in i.items():\n",
    "        if key == value[0]:\n",
    "            count +=1\n",
    "print (\"Prediction accuracy on the test file is {}\".format(count/len(test_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
