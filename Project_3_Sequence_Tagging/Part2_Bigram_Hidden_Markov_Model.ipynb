{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Construct the emission matrix p(w/t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Construct bag of word for word and tag seperately\n",
    "word_count = {}\n",
    "tag_count = {}\n",
    "with open (\"C:/Users/Xin/Desktop/Github-repo/Natural_Language_Processing_Projects/Project_3_Sequence_Tagging/hw3-data/train.txt\") as train_file:\n",
    "    for line in train_file:\n",
    "        line_list = line.split()\n",
    "        for i in range(len(line_list)):\n",
    "            temp = line_list[i].split('/')\n",
    "            if temp[0] not in word_count:\n",
    "                word_count[temp[0]]=1\n",
    "            if temp[0] in word_count:\n",
    "                word_count[temp[0]]+=1\n",
    "            if temp[1] not in tag_count:\n",
    "                tag_count[temp[1]]=1\n",
    "            if temp[1] in tag_count:\n",
    "                tag_count[temp[1]]+=1\n",
    "\n",
    "#word_count = {}\n",
    "#{'spoke': 6,\n",
    "# 'finished': 53,\n",
    "# 'sucker': 5,\n",
    "# ...\n",
    "# ...\n",
    "\n",
    "#tag_count = {}\n",
    "# {'A': 3031, 'D': 65382, 'E': 8625, 'F': 78056, 'N': 1333610, 'R': 101735}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Construct the tree structure to store the c(t,w). \n",
    "# Use the dictionary to store the counts\n",
    "# For the dictionary word_tag_pair_counts, the keys are the tags in the training set, the value is a dictionary, in which the keys \n",
    "# are the words, the the value are the counts for this word-key pair \n",
    "tag_word_pair_counts = {}\n",
    "with open (\"C:/Users/Xin/Desktop/Github-repo/Natural_Language_Processing_Projects/Project_3_Sequence_Tagging/hw3-data/train.txt\") as train_file:\n",
    "    for line in train_file:\n",
    "        line_list = line.split()\n",
    "        for i in range(len(line_list)):\n",
    "            temp = line_list[i].split('/')\n",
    "            if temp[1] not in tag_word_pair_counts:\n",
    "                tag_word_pair_counts[temp[1]] = {}\n",
    "                tag_word_pair_counts[temp[1]][temp[0]] = 1\n",
    "            else:\n",
    "                if temp[0] not in tag_word_pair_counts[temp[1]]:\n",
    "                    tag_word_pair_counts[temp[1]][temp[0]] = 1\n",
    "                else:\n",
    "                    tag_word_pair_counts[temp[1]][temp[0]] += 1 \n",
    "#tag_word_pair_counts\n",
    "#{'A': {',': 389,\n",
    "#  '--': 17,\n",
    "#  '.': 40,\n",
    "#  '?': 7,\n",
    "#  '[inaudible]': 2,\n",
    "#  'a': 61,\n",
    "#  ...\n",
    "#  ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Construct the emission matrix, each entry is p(w/t), I use add one smoothing to deal with unknown word\n",
    "\n",
    "## I use a dictionary of dictionary to represent this matrix\n",
    "## The key of the outer dictionary is the tag, and the the key of the sub-dictionary is their corresponding word\n",
    "emission_matrix = {}\n",
    "delta = 1\n",
    "V = len(word_count) + delta ## assum only one kind of unseen words\n",
    "for tag in tag_count:\n",
    "    emission_matrix[tag]={}\n",
    "    sum_tag_allword = 0\n",
    "    for word in tag_word_pair_counts[tag]:\n",
    "        sum_tag_allword += tag_word_pair_counts[tag][word]\n",
    "    sum_tag_allword += V ## Add one smoothing\n",
    "    for word in tag_word_pair_counts[tag]:\n",
    "        emission_matrix[tag][word] = (tag_word_pair_counts[tag][word]+delta)/sum_tag_allword\n",
    "    emission_matrix[tag]['unk'] = delta/V\n",
    "\n",
    "# emission_matrix\n",
    "#{'A': {',': 0.12838283828382838,\n",
    "#  '--': 0.005610561056105611,\n",
    "#  '.': 0.013201320132013201,\n",
    "#  '?': 0.0023102310231023103,\n",
    "#  '[inaudible]': 0.0006600660066006601,\n",
    "#  ....\n",
    "#  ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(you/A): 0.001238257899231426\n",
      "p(you/D): 0.16764407550337526\n",
      "p(you/E): 0.00031019507823809193\n",
      "p(you/F): 2.0315912438417392e-05\n",
      "p(you/N): 0.012762934093747484\n",
      "p(you/R): 0.010792309455962792\n"
     ]
    }
   ],
   "source": [
    "## Obtain p(you/t)\n",
    "print (\"p(you/A): {}\".format(emission_matrix['A']['you']))\n",
    "print (\"p(you/D): {}\".format(emission_matrix['D']['you']))\n",
    "print (\"p(you/E): {}\".format(emission_matrix['E']['you']))\n",
    "print (\"p(you/F): {}\".format(emission_matrix['F']['you']))\n",
    "print (\"p(you/N): {}\".format(emission_matrix['N']['you']))\n",
    "print (\"p(you/R): {}\".format(emission_matrix['R']['you']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construct transtion matrix p(t'/t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Considering the start and stop tag, there are 8 different tags ['A', 'D', 'E', 'F', 'N', 'R', <s>, </s>]\n",
    "## t =  ['A', 'D', 'E', 'F', 'N', 'R', <s>]\n",
    "## t' = ['A', 'D', 'E', 'F', 'N', 'R', </s>]\n",
    "\n",
    "## Construct a matrix to store the counts of c(t',t) \n",
    "## I use a dictionary of dictionary to represent this matrix\n",
    "## The key of the outer dictionary is t, and the the key of the sub-dictionary is t'\n",
    "\n",
    "tag_tag_count = {}\n",
    "with open (\"C:/Users/Xin/Desktop/Github-repo/Natural_Language_Processing_Projects/Project_3_Sequence_Tagging/hw3-data/train.txt\") as train_file:\n",
    "    for line in train_file:\n",
    "        line_list = line.split()\n",
    "        temp_tag_list = []\n",
    "        temp_tag_list.append(\"<s>\")\n",
    "        for i in range(len(line_list)):\n",
    "            temp = line_list[i].split('/')\n",
    "            temp_tag_list.append(temp[1])\n",
    "        temp_tag_list.append(\"</s>\")\n",
    "        for i in range(len(temp_tag_list)-1): ## i go through all the t in one sentence\n",
    "            if temp_tag_list[i] not in tag_tag_count:\n",
    "                tag_tag_count[temp_tag_list[i]]={}\n",
    "                tag_tag_count[temp_tag_list[i]][temp_tag_list[i+1]]=1\n",
    "            else:\n",
    "                if temp_tag_list[i+1] not in tag_tag_count[temp_tag_list[i]]:\n",
    "                    tag_tag_count[temp_tag_list[i]][temp_tag_list[i+1]]=1\n",
    "                else:\n",
    "                    tag_tag_count[temp_tag_list[i]][temp_tag_list[i+1]]+=1\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s>': {'A': 28, 'D': 11005, 'E': 1978, 'F': 12612, 'N': 153233, 'R': 11318},\n",
       " 'A': {'</s>': 46, 'A': 2564, 'D': 19, 'E': 2, 'F': 46, 'N': 305, 'R': 48},\n",
       " 'D': {'</s>': 4751,\n",
       "  'A': 38,\n",
       "  'D': 38134,\n",
       "  'E': 114,\n",
       "  'F': 736,\n",
       "  'N': 18923,\n",
       "  'R': 2685},\n",
       " 'E': {'</s>': 186, 'A': 1, 'D': 142, 'E': 5354, 'F': 64, 'N': 2378, 'R': 499},\n",
       " 'F': {'</s>': 6014,\n",
       "  'A': 89,\n",
       "  'D': 1999,\n",
       "  'E': 83,\n",
       "  'F': 39789,\n",
       "  'N': 27764,\n",
       "  'R': 2317},\n",
       " 'N': {'</s>': 177367,\n",
       "  'A': 174,\n",
       "  'D': 11910,\n",
       "  'E': 653,\n",
       "  'F': 20663,\n",
       "  'N': 1101003,\n",
       "  'R': 21839},\n",
       " 'R': {'</s>': 1810,\n",
       "  'A': 136,\n",
       "  'D': 2172,\n",
       "  'E': 440,\n",
       "  'F': 4145,\n",
       "  'N': 30003,\n",
       "  'R': 63028}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Construct transition matrix\n",
    "## Construct the transition matrix to store the p(t'/t). The data structure is the same as that store c(t',t)\n",
    "transition_matrix = {}\n",
    "for tag in tag_tag_count:\n",
    "    transition_matrix[tag] = {}\n",
    "    sum_temp = 0\n",
    "    for taggg in tag_tag_count[tag]:\n",
    "        sum_temp += tag_tag_count[tag][taggg]\n",
    "    for taggg in tag_tag_count[tag]:\n",
    "        transition_matrix[tag][taggg] = tag_tag_count[tag][taggg]/sum_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s>': {'A': 0.0001472335860843228,\n",
       "  'D': 0.05786805767349901,\n",
       "  'E': 0.010401001188385373,\n",
       "  'F': 0.0663182138462671,\n",
       "  'N': 0.8057515748735369,\n",
       "  'R': 0.05951391883222733},\n",
       " 'A': {'</s>': 0.015181518151815182,\n",
       "  'A': 0.8462046204620463,\n",
       "  'D': 0.006270627062706271,\n",
       "  'E': 0.0006600660066006601,\n",
       "  'F': 0.015181518151815182,\n",
       "  'N': 0.10066006600660066,\n",
       "  'R': 0.015841584158415842},\n",
       " 'D': {'</s>': 0.07266637096404154,\n",
       "  'A': 0.0005812086080053838,\n",
       "  'D': 0.5832581330967712,\n",
       "  'E': 0.0017436258240161515,\n",
       "  'F': 0.011257093039262171,\n",
       "  'N': 0.2894265918233126,\n",
       "  'R': 0.041066976644590934},\n",
       " 'E': {'</s>': 0.021567717996289426,\n",
       "  'A': 0.00011595547309833024,\n",
       "  'D': 0.016465677179962893,\n",
       "  'E': 0.6208256029684601,\n",
       "  'F': 0.0074211502782931356,\n",
       "  'N': 0.2757421150278293,\n",
       "  'R': 0.05786178107606679},\n",
       " 'F': {'</s>': 0.077048235218756,\n",
       "  'A': 0.001140221638588175,\n",
       "  'D': 0.025610146691435527,\n",
       "  'E': 0.0010633527640766126,\n",
       "  'F': 0.5097559413234258,\n",
       "  'N': 0.3556979053231696,\n",
       "  'R': 0.02968419704054833},\n",
       " 'N': {'</s>': 0.13299775271462624,\n",
       "  'A': 0.00013047302470214282,\n",
       "  'D': 0.008930653587370812,\n",
       "  'E': 0.0004896487651178119,\n",
       "  'F': 0.015494046605864238,\n",
       "  'N': 0.8255815610122608,\n",
       "  'R': 0.01637586429005803},\n",
       " 'R': {'</s>': 0.017791495468574912,\n",
       "  'A': 0.0013368195490199933,\n",
       "  'D': 0.021349794562289894,\n",
       "  'E': 0.004325004423299979,\n",
       "  'F': 0.040743507578587294,\n",
       "  'N': 0.29491615389152104,\n",
       "  'R': 0.6195372245267069}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decoding on the test file -- Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Viterbi Algorithm Implementation\n",
    "## Dynamic Programming\n",
    "\n",
    "tag_list = ['<s>', 'A', 'D', 'E', 'F', 'N', 'R', '</s>']\n",
    "count_correct_prediction = 0\n",
    "count_totalword = 0\n",
    "with open (\"C:/Users/Xin/Desktop/Github-repo/Natural_Language_Processing_Projects/Project_3_Sequence_Tagging/hw3-data/test.txt\") as test_file:\n",
    "    for line in test_file:\n",
    "        word_eachline = []\n",
    "        tag_eachline = []\n",
    "        tag_eachline.append(\"<s>\")\n",
    "        line_list = line.split()\n",
    "        for item in line_list:\n",
    "            temp = item.split('/')\n",
    "            word_eachline.append(temp[0])\n",
    "            tag_eachline.append(temp[1])\n",
    "        tag_eachline.append('</s>')\n",
    "        ## Use Viterbi Algorithm\n",
    "        ## Viterbi matrix is len(tag_list)*len(word_eachline)\n",
    "        viterbi = np.zeros((len(tag_list),len(word_eachline))) ## intialize the viterbi matrx all ones \n",
    "        backpointer = np.zeros((len(tag_list),len(word_eachline)),dtype=int)\n",
    "        for i in range(1, len(tag_list)-1):\n",
    "            ## Get the entries for the first column in Viterbi matrix\n",
    "            if tag_list[i] in transition_matrix[\"<s>\"] and word_eachline[0] in emission_matrix[tag_list[i]]:\n",
    "                viterbi[i,0] = transition_matrix[\"<s>\"][tag_list[i]]*emission_matrix[tag_list[i]][word_eachline[0]]\n",
    "            \n",
    "            if tag_list[i] not in transition_matrix[\"<s>\"] and word_eachline[0] in emission_matrix[tag_list[i]]:\n",
    "                viterbi[i,0] = 0\n",
    "            \n",
    "            if tag_list[i] in transition_matrix[\"<s>\"] and word_eachline[0] not in emission_matrix[tag_list[i]]:\n",
    "                viterbi[i,0] = transition_matrix[\"<s>\"][tag_list[i]]*emission_matrix[tag_list[i]][\"unk\"]\n",
    "                \n",
    "            if tag_list[i] not in transition_matrix[\"<s>\"] and word_eachline[0] not in emission_matrix[tag_list[i]]:\n",
    "                viterbi[i,0] = 0\n",
    "                \n",
    "            backpointer[i,0] = 0 ## 0 means the previous tag is '<s>'\n",
    "            \n",
    "        ## Calculate other entries\n",
    "        for i in range(1,len(word_eachline)):\n",
    "            for j in range(1, len(tag_list)-1):\n",
    "                temp1 = []\n",
    "                temp2 = []\n",
    "                for k in range(1, len(tag_list)-1):\n",
    "                    if tag_list[j] in transition_matrix[tag_list[k]] and word_eachline[i] in emission_matrix[tag_list[j]]:\n",
    "                        temp1.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]]*emission_matrix[tag_list[j]][word_eachline[i]])\n",
    "                        temp2.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]])\n",
    "                    if tag_list[j] not in transition_matrix[tag_list[k]] and word_eachline[i] in emission_matrix[tag_list[j]]:\n",
    "                        temp1.append(0)\n",
    "                        temp2.append(0)\n",
    "                    if tag_list[j] in transition_matrix[tag_list[k]] and word_eachline[i] not in emission_matrix[tag_list[j]]:\n",
    "                        temp1.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]]*emission_matrix[tag_list[j]]['unk'])\n",
    "                        temp2.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]])\n",
    "                    if tag_list[j] not in transition_matrix[tag_list[k]] and word_eachline[i] not in emission_matrix[tag_list[j]]:\n",
    "                        temp1.append(0)\n",
    "                        temp2.append(0)\n",
    "                viterbi[j,i] = max(temp1)\n",
    "                backpointer[j,i]= temp2.index(max(temp2))+1  ## here if there are more than one largest values in temp2, the index function only get the smallest index\n",
    "                \n",
    "        ## Temination step\n",
    "        temp = []\n",
    "        for i in range(1, len(tag_list)-1):\n",
    "            if \"</s>\" in transition_matrix[tag_list[i]]:\n",
    "                temp.append(viterbi[i,-1]*transition_matrix[tag_list[i]]['</s>'])\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        viterbi[tag_list.index(\"</s>\"),-1] = max(temp)\n",
    "        backpointer[tag_list.index(\"</s>\"),-1] = temp.index(max(temp))+1\n",
    "        \n",
    "        ## Backtrack to get the tag sequence\n",
    "        predict_eachline = [\"</s>\"]\n",
    "        predict_eachline.append(tag_list[backpointer[-1,-1]])\n",
    "        prev = backpointer[-1,-1]\n",
    "\n",
    "        for i in range(len(word_eachline)-1, 0, -1):\n",
    "            predict_eachline.append(tag_list[backpointer[prev,i]])\n",
    "            prev = backpointer[prev,i]\n",
    "        predict_eachline.append(tag_list[backpointer[prev,0]])\n",
    "        predict_eachline = predict_eachline[::-1]\n",
    "        \n",
    "        ## Count the correct prediction\n",
    "        for i in range(len(predict_eachline)):\n",
    "            count_totalword += 1\n",
    "            if predict_eachline[i] == tag_eachline[i]:\n",
    "                count_correct_prediction += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy by bigram hidden Markov model is : 0.8980215955104071.\n"
     ]
    }
   ],
   "source": [
    "print (\"The prediction accuracy by bigram hidden Markov model is : {}.\".format(count_correct_prediction/count_totalword))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction on the second line of text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_list = ['<s>', 'A', 'D', 'E', 'F', 'N', 'R', '</s>']\n",
    "with open (\"C:/Users/Xin/Desktop/Github-repo/Natural_Language_Processing_Projects/Project_3_Sequence_Tagging/hw3-data/test.txt\") as test_file:\n",
    "    line = next(test_file)\n",
    "    line = next(test_file)\n",
    "    word_eachline = []\n",
    "    tag_eachline = []\n",
    "    tag_eachline.append(\"<s>\")\n",
    "    line_list = line.split()\n",
    "    for item in line_list:\n",
    "        temp = item.split('/')\n",
    "        word_eachline.append(temp[0])\n",
    "        tag_eachline.append(temp[1])\n",
    "    tag_eachline.append('</s>')\n",
    "        ## Use Viterbi Algorithm\n",
    "        ## Viterbi matrix is len(tag_list)*len(word_eachline)\n",
    "    viterbi = np.zeros((len(tag_list),len(word_eachline))) ## intialize the viterbi matrx all ones \n",
    "    backpointer = np.zeros((len(tag_list),len(word_eachline)),dtype=int)\n",
    "    for i in range(1, len(tag_list)-1):\n",
    "            ## Get the entries for the first column in Viterbi matrix\n",
    "        if tag_list[i] in transition_matrix[\"<s>\"] and word_eachline[0] in emission_matrix[tag_list[i]]:\n",
    "            viterbi[i,0] = transition_matrix[\"<s>\"][tag_list[i]]*emission_matrix[tag_list[i]][word_eachline[0]]\n",
    "            \n",
    "        if tag_list[i] not in transition_matrix[\"<s>\"] and word_eachline[0] in emission_matrix[tag_list[i]]:\n",
    "            viterbi[i,0] = 0\n",
    "            \n",
    "        if tag_list[i] in transition_matrix[\"<s>\"] and word_eachline[0] not in emission_matrix[tag_list[i]]:\n",
    "            viterbi[i,0] = transition_matrix[\"<s>\"][tag_list[i]]*emission_matrix[tag_list[i]][\"unk\"]\n",
    "                \n",
    "        if tag_list[i] not in transition_matrix[\"<s>\"] and word_eachline[0] not in emission_matrix[tag_list[i]]:\n",
    "            viterbi[i,0] = 0\n",
    "                \n",
    "        backpointer[i,0] = 0 ## 0 means the previous tag is '<s>'\n",
    "            \n",
    "        ## Calculate other entries\n",
    "    for i in range(1,len(word_eachline)):\n",
    "        for j in range(1, len(tag_list)-1):\n",
    "            temp1 = []\n",
    "            temp2 = []\n",
    "            for k in range(1, len(tag_list)-1):\n",
    "                if tag_list[j] in transition_matrix[tag_list[k]] and word_eachline[i] in emission_matrix[tag_list[j]]:\n",
    "                    temp1.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]]*emission_matrix[tag_list[j]][word_eachline[i]])\n",
    "                    temp2.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]])\n",
    "                if tag_list[j] not in transition_matrix[tag_list[k]] and word_eachline[i] in emission_matrix[tag_list[j]]:\n",
    "                    temp1.append(0)\n",
    "                    temp2.append(0)\n",
    "                if tag_list[j] in transition_matrix[tag_list[k]] and word_eachline[i] not in emission_matrix[tag_list[j]]:\n",
    "                    temp1.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]]*emission_matrix[tag_list[j]]['unk'])\n",
    "                    temp2.append(viterbi[k,i-1]*transition_matrix[tag_list[k]][tag_list[j]])\n",
    "                if tag_list[j] not in transition_matrix[tag_list[k]] and word_eachline[i] not in emission_matrix[tag_list[j]]:\n",
    "                    temp1.append(0)\n",
    "                    temp2.append(0)\n",
    "            viterbi[j,i] = max(temp1)\n",
    "            backpointer[j,i]= temp2.index(max(temp2))+1  ## here if there are more than one largest values in temp2, the index function only get the smallest index\n",
    "                \n",
    "        ## Temination step\n",
    "    temp = []\n",
    "    for i in range(1, len(tag_list)-1):\n",
    "        if \"</s>\" in transition_matrix[tag_list[i]]:\n",
    "            temp.append(viterbi[i,-1]*transition_matrix[tag_list[i]]['</s>'])\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    viterbi[tag_list.index(\"</s>\"),-1] = max(temp)\n",
    "    backpointer[tag_list.index(\"</s>\"),-1] = temp.index(max(temp))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  7.22087229e-09   8.54442053e-09   1.24467683e-11   2.13591348e-12\n",
      "    9.08452474e-16   5.94699086e-16   8.37429019e-18   2.84384261e-20\n",
      "    2.40692558e-20   1.44386493e-21   9.86114203e-25   9.97639755e-28\n",
      "    3.76469650e-31   1.36062372e-34   5.64671937e-39   7.95699918e-41\n",
      "    1.02047600e-44   1.96864752e-43]\n",
      " [  2.69872370e-06   2.85351644e-06   2.20685553e-07   3.18703916e-08\n",
      "    9.11655964e-13   1.98607222e-13   2.54652472e-14   2.48686900e-15\n",
      "    3.59142173e-16   1.46533859e-20   6.62601416e-25   1.88897720e-27\n",
      "    4.95372265e-30   9.31323478e-33   2.66406078e-37   3.84731394e-38\n",
      "    1.10052827e-42   6.57454539e-41]\n",
      " [  5.10103050e-07   3.60360200e-08   9.36966312e-12   2.89781750e-11\n",
      "    2.72535742e-15   2.50813827e-15   1.95641006e-18   1.37732393e-20\n",
      "    3.26550261e-19   6.47058758e-20   1.97013557e-24   1.03568607e-28\n",
      "    6.99493055e-31   5.10624879e-34   1.55472780e-38   7.26888533e-40\n",
      "    2.21319770e-44   8.30275395e-43]\n",
      " [  4.50003219e-04   8.52183192e-05   3.53013719e-09   9.22901191e-10\n",
      "    3.13206147e-11   5.93126899e-12   6.14251533e-17   8.47579892e-21\n",
      "    1.04000209e-17   1.07704250e-22   2.41783815e-24   3.27724062e-27\n",
      "    1.80761757e-29   1.61577977e-32   4.13783431e-37   7.83592807e-38\n",
      "    1.03681428e-38   1.96344307e-39]\n",
      " [  4.46317672e-05   1.30111590e-05   1.55141920e-08   5.19196063e-09\n",
      "    1.36250305e-14   9.05587962e-13   2.69264720e-14   8.48648070e-17\n",
      "    5.85073457e-17   3.18184921e-18   4.31281369e-21   2.37880543e-23\n",
      "    2.12634893e-26   5.44534580e-31   1.29488653e-35   8.68981947e-37\n",
      "    7.41789071e-42   2.99779087e-40]\n",
      " [  2.91877974e-06   4.40704973e-06   1.56499292e-10   2.99001702e-09\n",
      "    9.08497717e-14   3.06734487e-13   2.05089961e-15   1.09244627e-18\n",
      "    3.36940073e-17   1.15172835e-18   3.68092520e-22   3.29772227e-24\n",
      "    8.53199590e-28   8.65659340e-33   4.37333222e-37   8.93895809e-38\n",
      "    2.71604575e-42   1.01539098e-40]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.51279823e-40]]\n"
     ]
    }
   ],
   "source": [
    "print (viterbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 4 4 2 2 4 4 2 2 2 6 1 6 5 1 1 6 4]\n",
      " [0 4 4 2 2 4 4 2 2 2 5 5 5 5 2 2 2 4]\n",
      " [0 4 4 2 2 4 4 2 2 2 3 5 6 5 3 3 3 4]\n",
      " [0 4 4 2 4 4 4 5 2 4 5 5 5 5 5 4 4 4]\n",
      " [0 4 4 2 2 4 4 5 2 2 5 5 5 5 5 5 5 4]\n",
      " [0 4 6 2 6 4 6 6 2 6 6 6 6 6 5 6 6 4]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "print(backpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_2ndline = [\"</s>\"]\n",
    "pred_2ndline.append(tag_list[backpointer[-1,-1]])\n",
    "prev = backpointer[-1,-1]\n",
    "\n",
    "for i in range (len(word_eachline)-1, 0, -1):\n",
    "    pred_2ndline.append(tag_list[backpointer[prev,i]])\n",
    "    prev = backpointer[prev,i]\n",
    "pred_2ndline.append(tag_list[backpointer[prev,0]])\n",
    "pred_2ndline = pred_2ndline[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction on the second line of test file is: ['<s>', 'F', 'F', 'D', 'F', 'F', 'F', 'D', 'D', 'D', 'N', 'N', 'N', 'N', 'N', 'F', 'F', 'F', 'F', '</s>'].\n"
     ]
    }
   ],
   "source": [
    "print(\"The prediction on the second line of test file is: {}.\".format(pred_2ndline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log probability of this model output is: -91.68944264948114.\n"
     ]
    }
   ],
   "source": [
    "print(\"The log probability of this model output is: {}.\".format(np.log(viterbi[-1,-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "pred.append(tag_list[backpointer[-1,-1]])\n",
    "prev = backpointer[-1,-1]\n",
    "\n",
    "for i in range (len(word_eachline)-1, 0, -1):\n",
    "    pred.append(tag_list[backpointer[prev,i]])\n",
    "    prev = backpointer[prev,i]\n",
    "pred = pred[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'F', 'D', 'F', 'F', 'F', 'D', 'D', 'D', 'N', 'N', 'N', 'N', 'N', 'F', 'F', 'F', 'F']\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'guess', \"it's\", 'pretty', 'deep']\n"
     ]
    }
   ],
   "source": [
    "output_label_N = []\n",
    "for i in range(1,len(pred_2ndline)-1):\n",
    "    if pred_2ndline[i] == 'N':\n",
    "        output_label_N.append(word_eachline[i-1])\n",
    "print (output_label_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
